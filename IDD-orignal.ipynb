{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19769,
     "status": "ok",
     "timestamp": 1624006759859,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "mbnfkiGl4ma5",
    "outputId": "1b3998c8-034b-436b-bcd8-23f3f52f606b"
   },
   "outputs": [],
   "source": [
    "#Mounting my Google Drive to get access to the data files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n",
    "\n",
    "# This creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
    "!ln -s /content/gdrive/My\\ Drive/Project/ /mydrive\n",
    "!ls /mydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xolII-V6U2k"
   },
   "outputs": [],
   "source": [
    "#Unzipping the dataset to the current directory which is /content/\n",
    "!unzip -q '/mydrive/data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmKMvf-t04Ls"
   },
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import os            #For Searching and accessing files in the directories\n",
    "import cv2           #To Read and write images\n",
    "import numpy as np   #To perform matrix operations on image arrays\n",
    "from tensorflow.keras.models import load_model, Model      #To design and deploy deep learning models\n",
    "from sklearn.cluster import KMeans                         #Clustering algorithm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input  #VGG16 model for transfer learning\n",
    "from tensorflow.keras.preprocessing import image                         #Tensor operaitons on images\n",
    "from keras.utils.vis_utils import plot_model                             #To plot the model\n",
    "import matplotlib.image as mpimg              #Plotting images\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score         #Cluster performance evaluation\n",
    "from tabulate import tabulate      #For displaying results\n",
    "\n",
    "%matplotlib inline                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQZnblnj1IMs"
   },
   "outputs": [],
   "source": [
    "#Model function\n",
    "def get_model(layer='fc2'):\n",
    "\n",
    "    base_model = VGG16(weights='imagenet', include_top=True) #VGG model import trained with imagenet dataset\n",
    "    model = Model(inputs=base_model.input,                   #Creating the model with layer 'fc2' as an output layer\n",
    "                outputs=base_model.get_layer(layer).output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fS2jwvSg4_tU"
   },
   "outputs": [],
   "source": [
    "#Function to access the image files form the dataset\n",
    "def get_files(path_to_files, size):\n",
    "    fn_imgs = []\n",
    "    files = [file for file in os.listdir(path_to_files)]       #Storing all image files names\n",
    "    for file in files:\n",
    "        img = cv2.resize(cv2.imread(path_to_files+file), size) #Reading and resizing each image\n",
    "        fn_imgs.append([file, img])             #Accumulating each image to a variable          \n",
    "    return dict(fn_imgs)                        #Returning the dictionary of all the image and their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5x34cDV5K_S"
   },
   "outputs": [],
   "source": [
    "#Obtaining features from each image\n",
    "def feature_vector(img_arr, model):          #Function takes the image array and the VGG model as input\n",
    "    if img_arr.shape[2] == 1:       \n",
    "      img_arr = img_arr.repeat(3, axis=2)    #Repeat grayscale pixel values to three color channels\n",
    "  \n",
    "    arr4d = np.expand_dims(img_arr, axis=0)  #Expanding image dimension (1, 224, 224, 3) to make it compatable with keras model\n",
    "    arr4d_pp = preprocess_input(arr4d)\n",
    "    return model.predict(arr4d_pp)[0,:]      #Returning image features through VGG16 net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdW4X-mf5mAQ"
   },
   "outputs": [],
   "source": [
    "#Extracting features from all the images\n",
    "def feature_vectors(imgs_dict, model):\n",
    "    f_vect = {}\n",
    "    for fn, img in imgs_dict.items():         #For loop over each image in the imgs_dict\n",
    "      f_vect[fn] = feature_vector(img, model) #Calling feature vector function to extract the features\n",
    "    return f_vect                             #Returning features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11053,
     "status": "ok",
     "timestamp": 1624006782284,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "bcfQ_KVAlpyV",
    "outputId": "86d448bc-061b-4e19-c556-b9c2d021d0f5"
   },
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model = get_model()     #Calling model function\n",
    "\n",
    "#Model summary\n",
    "model.summary()\n",
    "\n",
    "#Plotting the model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRb-_t1j5xRY"
   },
   "outputs": [],
   "source": [
    "img_path = '/content/data/'      #Path to image dataset\n",
    "\n",
    "imgs_dict = get_files(path_to_files = img_path ,size = (224, 224))   #Getting image files and resizing\n",
    "\n",
    "# Feed images through the model and extract feature vectors.\n",
    "img_feature_vector = feature_vectors(imgs_dict, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "executionInfo": {
     "elapsed": 685627,
     "status": "ok",
     "timestamp": 1624007661055,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "HqfA67ve6vge",
    "outputId": "6be19c71-f7e8-41c5-d924-1afcca0621ae"
   },
   "outputs": [],
   "source": [
    "''' In this code cell we determine the optimal number of clusters to be detected\n",
    "    in our image dataset. The method used for it is called the elbow method. In \n",
    "    this method we perform the clustering algorithm for a range of cluster values\n",
    "    and then calculate the variance in each cluster. The variance is then plotted\n",
    "    agains the cluster numbers. The point where the curve bends and makes an\n",
    "    elbow shape is then choosen to be optimal number of clusters since after\n",
    "    this point the variance decreases very slowly.'''\n",
    "\n",
    "images = list(img_feature_vector.values())    #Image feature vectors\n",
    "fns = list(img_feature_vector.keys())         #Image file names\n",
    "sum_of_squared_distances = []                 #Initializing the variance\n",
    "K = range(1, 30)                              #Range of clusters to be tried\n",
    "for k in K:                                   #For loop over the cluster range\n",
    "    km = KMeans(n_clusters=k)                 #KNN object with cluster number\n",
    "    km = km.fit(images)                       #Running cluster algorithm\n",
    "    sum_of_squared_distances.append(km.inertia_)   #Calculating the variance\n",
    "\n",
    "#Plotting the variance\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0DK-P2I7H1K"
   },
   "outputs": [],
   "source": [
    "#Running clustering algorithm with optimal number of clusters\n",
    "n_clusters = 3    #Optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, init='k-means++')  #Initializing clustering object\n",
    "kmeans.fit(images)                     #Fitting the clustering object to the dataset\n",
    "y_kmeans = kmeans.predict(images)      #Predicting clusters for each image in the dataset\n",
    "file_names = list(imgs_dict.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPv9EI-U7WVw"
   },
   "outputs": [],
   "source": [
    "cluster_path = img_path    #Path to store the clusters\n",
    "path_to_files = img_path   #Path to image dataset\n",
    "\n",
    "#Creating each cluster directory\n",
    "for c in range(0,n_clusters):\n",
    "    if not os.path.exists(cluster_path+'cluster_'+str(c)):\n",
    "        os.mkdir(cluster_path+'cluster_'+str(c))\n",
    "\n",
    "#Storing each image to different clusters it belongs to \n",
    "for fn, cluster in zip(file_names, y_kmeans):\n",
    "    image = cv2.imread(path_to_files+fn)\n",
    "    cv2.imwrite(cluster_path+'cluster_'+str(cluster)+'/'+fn, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 3715,
     "status": "ok",
     "timestamp": 1624007687878,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "1JsUCkc69sYE",
    "outputId": "e38c98b6-ec9d-4a27-f3d3-08aa50b2e895"
   },
   "outputs": [],
   "source": [
    "'''In this cell code we evaluate the performance of our clustering algorithm.\n",
    "   since clustering is an unsupervised learning technique, thus there is no \n",
    "   direct method to evaluate its performance since we dont have the ground truth\n",
    "   available. The performance metric used here is called the silhouette analysis.\n",
    "   It is basically a measure of how similar the members in the same cluster are\n",
    "   and how different they are from the neighbour clusters.'''\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))        #Empty figure\n",
    "\n",
    "# The silhouette coefficient can range from -1, 1 but in this example all\n",
    "# lie within [-0.1, 0.5]   \n",
    "ax.set_xlim([-0.1, 0.5])                               #X-axis limit\n",
    "ax.set_ylim([0, len(images) + (n_clusters + 1) * 10])  #Y-axis limit\n",
    "\n",
    "# Compute the silhouette scores for each image\n",
    "sample_silhouette_values = silhouette_samples(images, y_kmeans)\n",
    "# Compute the average silhouette score\n",
    "silhouette_avg = silhouette_score(images, y_kmeans)\n",
    "\n",
    "y_lower = 10\n",
    "#For loop over each image in the respective cluster\n",
    "for i in range(n_clusters):\n",
    "  # Aggregate the silhouette scores for samples belonging to\n",
    "  # cluster i, and sort them\n",
    "  ith_cluster_silhouette_values = \\\n",
    "      sample_silhouette_values[y_kmeans == i]\n",
    "\n",
    "  ith_cluster_silhouette_values.sort() #Sorting each cluster score\n",
    "  \n",
    "  #Setting limit for each cluster in y-axis\n",
    "  size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "  y_upper = y_lower + size_cluster_i\n",
    "  \n",
    "  #Setting color for each cluster's silhouette coefficients\n",
    "  color = cm.nipy_spectral(float(i) / n_clusters) \n",
    "  ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "  # Label the silhouette plots with their cluster numbers at the middle\n",
    "  ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "  # Compute the new y_lower for next plot\n",
    "  y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "#Titles for the plot\n",
    "ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "# The vertical line for average silhouette score of all the values\n",
    "ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold');\n",
    "\n",
    "#Printing the average silhouette score for the clusters\n",
    "print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "executionInfo": {
     "elapsed": 3624,
     "status": "ok",
     "timestamp": 1624007691485,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "TmxcbYmy70cW",
    "outputId": "c45821a7-b525-43b8-dc40-e79c04299dd6"
   },
   "outputs": [],
   "source": [
    "#Plotting images in each cluster\n",
    "fig = plt.figure(figsize=(14, 14))    #Empty figure\n",
    " \n",
    "cluster_no = 'cluster_0/'             #Cluster number to be plotted\n",
    "\n",
    "cluster_path = img_path + cluster_no  #Path to specified cluster images\n",
    "images = [file for file in os.listdir(cluster_path)]  #Image file names in the specified cluster path\n",
    "\n",
    "for cnt, data in enumerate(images[1:30]): #For loop over the first 30 images in the cluster\n",
    "    y = fig.add_subplot(6, 5, cnt+1)      #Creating subplots\n",
    "    img = mpimg.imread(cluster_path+data) #Reading the image\n",
    "    y.imshow(img)                         #Plotting the image\n",
    "    plt.title(cluster_no)                 #Cluster number as a title over the image\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "cluster0_imgs_total = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "executionInfo": {
     "elapsed": 2094,
     "status": "ok",
     "timestamp": 1624007693570,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "SREcZRA5TByC",
    "outputId": "843a8603-9940-4d8a-98fc-141984555733"
   },
   "outputs": [],
   "source": [
    "#Plotting images in each cluster\n",
    "fig = plt.figure(figsize=(14, 14))    #Empty figure\n",
    " \n",
    "cluster_no = 'cluster_1/'             #Cluster number to be plotted\n",
    "\n",
    "cluster_path = img_path + cluster_no  #Path to specified cluster images\n",
    "images = [file for file in os.listdir(cluster_path)]  #Image file names in the specified cluster path\n",
    "\n",
    "for cnt, data in enumerate(images[1:30]): #For loop over the first 30 images in the cluster\n",
    "    y = fig.add_subplot(6, 5, cnt+1)      #Creating subplots\n",
    "    img = mpimg.imread(cluster_path+data) #Reading the image\n",
    "    y.imshow(img)                         #Plotting the image\n",
    "    plt.title(cluster_no)                 #Cluster number as a title over the image\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "cluster1_imgs_total = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "executionInfo": {
     "elapsed": 2119,
     "status": "ok",
     "timestamp": 1624007695677,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "WeAh4eq6c7nx",
    "outputId": "59b73948-9a50-4ac1-9d7d-afa1072ac097"
   },
   "outputs": [],
   "source": [
    "#Plotting images in each cluster\n",
    "fig = plt.figure(figsize=(14, 14))    #Empty figure\n",
    " \n",
    "cluster_no = 'cluster_2/'             #Cluster number to be plotted\n",
    "\n",
    "cluster_path = img_path + cluster_no  #Path to specified cluster images\n",
    "images = [file for file in os.listdir(cluster_path)]  #Image file names in the specified cluster path\n",
    "\n",
    "for cnt, data in enumerate(images[1:30]): #For loop over the first 30 images in the cluster\n",
    "    y = fig.add_subplot(6, 5, cnt+1)      #Creating subplots\n",
    "    img = mpimg.imread(cluster_path+data) #Reading the image\n",
    "    y.imshow(img)                         #Plotting the image\n",
    "    plt.title(cluster_no)                 #Cluster number as a title over the image\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "cluster2_imgs_total = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1624007841503,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "fvEt9GZeO9z5",
    "outputId": "02d33d9f-a51c-4d46-ab38-3ceef413fd25"
   },
   "outputs": [],
   "source": [
    "img_total = len(img_feature_vector)    #Total number of images in the dataset\n",
    "\n",
    "percent_dup_removed = (1-(n_clusters/img_total))*100     #Percent duplication removed\n",
    "  \n",
    "  \n",
    "# Creating dataset\n",
    "Clusters_t = ['Cluster_0', 'Cluster_1', 'Cluster_2']\n",
    "\n",
    "p_d_c0 = (cluster0_imgs_total/img_total)*percent_dup_removed       #Percent duplication in cluster0\n",
    "p_d_c1 = (cluster1_imgs_total/img_total)*percent_dup_removed       #Percent duplication in cluster1\n",
    "p_d_c2 = (cluster2_imgs_total/img_total)*percent_dup_removed       #Percent duplication in cluster2\n",
    "\n",
    "table = [['Category', 'Images', 'Duplication (%)'], ['Cluster_0', str(cluster0_imgs_total), p_d_c0], ['Cluster_1', str(cluster1_imgs_total), p_d_c1], ['Cluster_2', str(cluster2_imgs_total), p_d_c2],['Total', str(img_total), percent_dup_removed]]\n",
    "\n",
    "print('The details of overall duplication percentage and per are presented in the below table')\n",
    "print(tabulate(table, headers='firstrow', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1624007695687,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "d2j7hDiWBXS6",
    "outputId": "b20f3fd6-ba92-4923-9d2a-e13a6a7841e0"
   },
   "outputs": [],
   "source": [
    "data = [p_d_c0, p_d_c1, p_d_c2]\n",
    "  \n",
    "# Creating explode data\n",
    "explode = (0.1, 0.0, 0.2)\n",
    "  \n",
    "# Creating color parameters\n",
    "colors = (\"orange\", \"cyan\", \"brown\")\n",
    "  \n",
    "# Wedge properties\n",
    "wp = { 'linewidth' : 1, 'edgecolor' : \"green\" }\n",
    "  \n",
    "# Creating autocpt arguments\n",
    "def func(pct, allvalues):\n",
    "    absolute = int(pct / 100.*np.sum(allvalues))\n",
    "    return \"{:.1f}%\\n({:d} )\".format(pct, absolute)\n",
    "  \n",
    "# Creating plot\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "wedges, texts, autotexts = ax.pie(data, \n",
    "                                  autopct = lambda pct: func(pct, data),\n",
    "                                  explode = explode, \n",
    "                                  labels = Clusters_t,\n",
    "                                  shadow = True,\n",
    "                                  colors = colors,\n",
    "                                  startangle = 90,\n",
    "                                  wedgeprops = wp,\n",
    "                                  textprops = dict(color =\"magenta\"))\n",
    "  \n",
    "# Adding legend\n",
    "ax.legend(wedges, Clusters_t,\n",
    "          title =\"Clusters\",\n",
    "          loc =\"center left\",\n",
    "          bbox_to_anchor =(1, 0, 0.5, 1))\n",
    "  \n",
    "plt.setp(autotexts, size = 8, weight =\"bold\")\n",
    "ax.set_title(\"Percent Duplication removed per Cluster\")\n",
    "  \n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1624007944202,
     "user": {
      "displayName": "Naveed Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9KTptrjo4t4cF-SbGZiVMJXb_Y-oD_o3Bacrx=s64",
      "userId": "05394460902808852358"
     },
     "user_tz": -300
    },
    "id": "wW9YjLFkbBcL",
    "outputId": "09db75d8-6633-4d20-d33a-0a577dff1ae7"
   },
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "height = [cluster0_imgs_total, cluster1_imgs_total, cluster2_imgs_total]\n",
    "bars = ('Cluster_0','Cluster_1','Cluster_2')\n",
    "x_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars with different colors\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.bar(x_pos, height, color=['red', 'green', 'cyan'],edgecolor='blue')\n",
    "\n",
    "# Create names on the x-axis\n",
    "plt.xticks(x_pos, bars)\n",
    "plt.ylabel('Images')\n",
    "plt.xlabel('Clusters')\n",
    "plt.grid( linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "\n",
    "plt.title('Duplicate Images per Cluster')\n",
    "\n",
    "# Show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxzlmzEzaqRJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMsjqK/6TU3MLtr9jPR/ljc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
