{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cryptocurrency Price Prediction with LSTM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend to prevent chart popups\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from utils import download_crypto_data, scale_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Global configuration loaded successfully!\n",
      "üìä Data: BTCUSDT 5m from 2021 01 to 2021 01\n",
      "üß† Model: 50 units, 50 epochs, batch size 32\n",
      "üîß Features: 5 lag period, 10 candle sequence, no rolling windows\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GLOBAL CONFIGURATION PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "# Data Configuration\n",
    "SYMBOL = \"BTCUSDT\"                    # Trading pair symbol\n",
    "INTERVAL = \"5m\"                       # Time interval (1m, 5m, 15m, 1h, 4h, 1d)\n",
    "DATA_FROM = \"2021 01\"                 # Start date for data download (YYYY MM)\n",
    "DATA_TO = \"2021 01\"                   # End date for data download (YYYY MM)\n",
    "\n",
    "# Model Configuration\n",
    "LSTM_UNITS = 50                       # Number of LSTM units\n",
    "DROPOUT_RATE = 0.2                    # Dropout rate for regularization\n",
    "EPOCHS = 50                           # Number of training epochs\n",
    "BATCH_SIZE = 32                       # Batch size for training\n",
    "TEST_SIZE = 0.2                       # Proportion of data for testing (0.2 = 20%)\n",
    "\n",
    "# Feature Engineering Configuration\n",
    "LAG_PERIOD = 5                        # Single lag period for all columns\n",
    "SEQUENCE_LENGTH = 10                  # Number of previous candles to use for prediction\n",
    "\n",
    "# Prediction Configuration\n",
    "PREDICTION_LENGTH = 1                 # Number of future steps to predict\n",
    "SAMPLE_SIZE = 200                     # Number of samples for demonstration\n",
    "\n",
    "# Visualization Configuration\n",
    "MAX_POINTS = 2000                     # Maximum points to plot for performance\n",
    "MAX_SAMPLES = 1000                    # Maximum samples for prediction plots\n",
    "\n",
    "print(\"‚úÖ Global configuration loaded successfully!\")\n",
    "print(f\"üìä Data: {SYMBOL} {INTERVAL} from {DATA_FROM} to {DATA_TO}\")\n",
    "print(f\"üß† Model: {LSTM_UNITS} units, {EPOCHS} epochs, batch size {BATCH_SIZE}\")\n",
    "print(f\"üîß Features: {LAG_PERIOD} lag period, {SEQUENCE_LENGTH} candle sequence, no rolling windows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "This section contains functions to download and load cryptocurrency data from Binance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_range(from_date, to_date):\n",
    "    \"\"\"\n",
    "    Generate years and months from date range.\n",
    "    \n",
    "    Args:\n",
    "        from_date (str): Start date in \"YYYY MM\" format\n",
    "        to_date (str): End date in \"YYYY MM\" format\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (years, months) - lists of years and months to download\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    start_year, start_month = from_date.split()\n",
    "    end_year, end_month = to_date.split()\n",
    "    \n",
    "    start_year = int(start_year)\n",
    "    start_month = int(start_month)\n",
    "    end_year = int(end_year)\n",
    "    end_month = int(end_month)\n",
    "    \n",
    "    years = []\n",
    "    months = []\n",
    "    \n",
    "    current_year = start_year\n",
    "    current_month = start_month\n",
    "    \n",
    "    while (current_year < end_year) or (current_year == end_year and current_month <= end_month):\n",
    "        year_str = str(current_year)\n",
    "        month_str = f\"{current_month:02d}\"\n",
    "        \n",
    "        if year_str not in years:\n",
    "            years.append(year_str)\n",
    "        if month_str not in months:\n",
    "            months.append(month_str)\n",
    "        \n",
    "        # Move to next month\n",
    "        if current_month == 12:\n",
    "            current_year += 1\n",
    "            current_month = 1\n",
    "        else:\n",
    "            current_month += 1\n",
    "    \n",
    "    return years, months\n",
    "\n",
    "\n",
    "def load_data_by_date_range(symbol, interval, from_date, to_date):\n",
    "    \"\"\"\n",
    "    Load data for a specific date range, combining into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): Trading pair symbol\n",
    "        interval (str): Time interval\n",
    "        from_date (str): Start date in \"YYYY MM\" format\n",
    "        to_date (str): End date in \"YYYY MM\" format\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with all data in the date range\n",
    "    \"\"\"\n",
    "    years, months = generate_date_range(from_date, to_date)\n",
    "    print(f\"Loading data from {from_date} to {to_date}\")\n",
    "    print(f\"Years: {years}\")\n",
    "    print(f\"Months: {months}\")\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for year in years:\n",
    "        print(f\"Loading data for year {year}...\")\n",
    "        year_data = load_multiple_months_data(symbol, interval, year, months)\n",
    "        if year_data is not None:\n",
    "            all_data.append(year_data)\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        combined_df = combined_df.sort_values('Open time').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Total combined data shape: {combined_df.shape}\")\n",
    "        print(f\"Date range: {combined_df['Open time'].min()} to {combined_df['Open time'].max()}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No data loaded successfully\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• DOWNLOADING CRYPTOCURRENCY DATA\n",
      "   Symbol: BTCUSDT\n",
      "   Interval: 5m\n",
      "   Date range: 2021 01 to 2021 01\n",
      "   Max rows: 50,000\n",
      "==================================================\n",
      "üìÖ Date range: 2021 months 1 to 1\n",
      "üìä Will download months: ['01']\n",
      "üîÑ Loading data with memory efficiency (max 50,000 rows)...\n",
      "üì• Downloading BTCUSDT 5m data for 2021-01 from Binance Vision...\n",
      "‚úÖ Downloaded 8928 rows for 2021-01\n",
      "   Total rows: 8,928\n",
      "‚úÖ Data loading completed!\n",
      "   Final shape: (8928, 12)\n",
      "\\n‚úÖ Download completed successfully!\n",
      "üìä Final data shape: (8928, 12)\n",
      "üìÖ Date range: 2021-01-01 00:00:00 to 2021-01-31 23:55:00\n",
      "üíæ Memory usage: 0.8 MB\n",
      "\n",
      "üìã Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Quote asset volume</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Taker buy base asset volume</th>\n",
       "      <th>Taker buy quote asset volume</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>28923.63</td>\n",
       "      <td>29017.50</td>\n",
       "      <td>28913.12</td>\n",
       "      <td>28975.65</td>\n",
       "      <td>182.889878</td>\n",
       "      <td>2021-01-01 00:04:59.999</td>\n",
       "      <td>5.300787e+06</td>\n",
       "      <td>5614</td>\n",
       "      <td>80.029129</td>\n",
       "      <td>2.319247e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:05:00</td>\n",
       "      <td>28975.65</td>\n",
       "      <td>28979.53</td>\n",
       "      <td>28846.28</td>\n",
       "      <td>28858.94</td>\n",
       "      <td>214.568104</td>\n",
       "      <td>2021-01-01 00:09:59.999</td>\n",
       "      <td>6.201532e+06</td>\n",
       "      <td>4928</td>\n",
       "      <td>113.761331</td>\n",
       "      <td>3.287213e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 00:10:00</td>\n",
       "      <td>28858.94</td>\n",
       "      <td>28883.20</td>\n",
       "      <td>28690.17</td>\n",
       "      <td>28752.80</td>\n",
       "      <td>442.619587</td>\n",
       "      <td>2021-01-01 00:14:59.999</td>\n",
       "      <td>1.273741e+07</td>\n",
       "      <td>8776</td>\n",
       "      <td>199.913764</td>\n",
       "      <td>5.753595e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 00:15:00</td>\n",
       "      <td>28752.80</td>\n",
       "      <td>28852.48</td>\n",
       "      <td>28720.91</td>\n",
       "      <td>28820.72</td>\n",
       "      <td>174.839779</td>\n",
       "      <td>2021-01-01 00:19:59.999</td>\n",
       "      <td>5.034871e+06</td>\n",
       "      <td>5208</td>\n",
       "      <td>91.542596</td>\n",
       "      <td>2.635936e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 00:20:00</td>\n",
       "      <td>28822.17</td>\n",
       "      <td>28846.46</td>\n",
       "      <td>28744.09</td>\n",
       "      <td>28846.46</td>\n",
       "      <td>161.316784</td>\n",
       "      <td>2021-01-01 00:24:59.999</td>\n",
       "      <td>4.645146e+06</td>\n",
       "      <td>4630</td>\n",
       "      <td>78.111722</td>\n",
       "      <td>2.249406e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open time      Open      High       Low     Close      Volume  \\\n",
       "0 2021-01-01 00:00:00  28923.63  29017.50  28913.12  28975.65  182.889878   \n",
       "1 2021-01-01 00:05:00  28975.65  28979.53  28846.28  28858.94  214.568104   \n",
       "2 2021-01-01 00:10:00  28858.94  28883.20  28690.17  28752.80  442.619587   \n",
       "3 2021-01-01 00:15:00  28752.80  28852.48  28720.91  28820.72  174.839779   \n",
       "4 2021-01-01 00:20:00  28822.17  28846.46  28744.09  28846.46  161.316784   \n",
       "\n",
       "               Close time  Quote asset volume  Number of trades  \\\n",
       "0 2021-01-01 00:04:59.999        5.300787e+06              5614   \n",
       "1 2021-01-01 00:09:59.999        6.201532e+06              4928   \n",
       "2 2021-01-01 00:14:59.999        1.273741e+07              8776   \n",
       "3 2021-01-01 00:19:59.999        5.034871e+06              5208   \n",
       "4 2021-01-01 00:24:59.999        4.645146e+06              4630   \n",
       "\n",
       "   Taker buy base asset volume  Taker buy quote asset volume  Ignore  \n",
       "0                    80.029129                  2.319247e+06       0  \n",
       "1                   113.761331                  3.287213e+06       0  \n",
       "2                   199.913764                  5.753595e+06       0  \n",
       "3                    91.542596                  2.635936e+06       0  \n",
       "4                    78.111722                  2.249406e+06       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Bitcoin data using common download function\n",
    "btc_data = download_crypto_data(\n",
    "    symbol=SYMBOL,\n",
    "    interval=INTERVAL, \n",
    "    data_from=DATA_FROM,\n",
    "    data_to=DATA_TO,\n",
    "    max_rows=50000,  # Limit for memory efficiency\n",
    "    # Uses Binance Vision only\n",
    ")\n",
    "\n",
    "if btc_data is not None and not btc_data.empty:\n",
    "    print(f\"\\nüìã Sample Data:\")\n",
    "    display(btc_data.head())\n",
    "else:\n",
    "    print(\"‚ùå No data available for processing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This section handles feature engineering, scaling, and data preparation for LSTM training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series_features(df, lag_period=5):\n",
    "    \"\"\"\n",
    "    Create time series features for each candle with proper 5-minute interval encoding.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with OHLCV data\n",
    "        lag_period (int): Number of previous candles to use for lag features\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with time series features\n",
    "    \"\"\"\n",
    "    print(\"üîß Creating time series features...\")\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Time-based features for 5-minute intervals\n",
    "    # 5-minute intervals = 288 intervals per day (24 * 60 / 5)\n",
    "    print(\"‚è∞ Adding time-based features...\")\n",
    "    data['Hour'] = data['Open time'].dt.hour\n",
    "    data['Minute'] = data['Open time'].dt.minute\n",
    "    \n",
    "    # Calculate the 5-minute interval number within the day (0-287)\n",
    "    data['Interval_5min'] = data['Hour'] * 12 + data['Minute'] // 5\n",
    "    \n",
    "    # Cyclical encoding for 5-minute intervals\n",
    "    data['Interval_sin'] = np.sin(2 * np.pi * data['Interval_5min'] / 288)\n",
    "    data['Interval_cos'] = np.cos(2 * np.pi * data['Interval_5min'] / 288)\n",
    "    \n",
    "    # Also keep hour-based features for broader patterns\n",
    "    data['Hour_sin'] = np.sin(2 * np.pi * data['Hour'] / 24)\n",
    "    data['Hour_cos'] = np.cos(2 * np.pi * data['Hour'] / 24)\n",
    "    \n",
    "    # Price-based features\n",
    "    print(\"üí∞ Adding price-based features...\")\n",
    "    data['Price_Range'] = data['High'] - data['Low']\n",
    "    data['Price_Change'] = data['Close'] - data['Open']\n",
    "    data['Price_Change_Pct'] = (data['Close'] - data['Open']) / data['Open']\n",
    "    \n",
    "    # Volume features\n",
    "    data['Volume_MA_5'] = data['Volume'].rolling(window=5).mean()\n",
    "    data['Volume_MA_10'] = data['Volume'].rolling(window=10).mean()\n",
    "    \n",
    "    # Lag features for OHLCV\n",
    "    print(f\"üìä Creating lag features (lag period: {lag_period})...\")\n",
    "    ohlcv_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    for col in ohlcv_cols:\n",
    "        for lag in range(1, lag_period + 1):\n",
    "            data[f'{col}_Lag_{lag}'] = data[col].shift(lag)\n",
    "    \n",
    "    print(f\"‚úÖ Time series features created! Shape: {data.shape}\")\n",
    "    \n",
    "    # Show time feature examples\n",
    "    print(f\"\\n‚è∞ Time Feature Examples:\")\n",
    "    print(f\"   Hour range: {data['Hour'].min()}-{data['Hour'].max()}\")\n",
    "    print(f\"   5-min interval range: {data['Interval_5min'].min()}-{data['Interval_5min'].max()}\")\n",
    "    print(f\"   Interval_sin range: {data['Interval_sin'].min():.3f} to {data['Interval_sin'].max():.3f}\")\n",
    "    print(f\"   Interval_cos range: {data['Interval_cos'].min():.3f} to {data['Interval_cos'].max():.3f}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_sliding_windows(data, sequence_length=10, target_cols=['Open', 'High', 'Low', 'Close', 'Volume']):\n",
    "    \"\"\"\n",
    "    Create sliding windows for time series prediction.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame with features\n",
    "        sequence_length (int): Number of previous candles to use for prediction\n",
    "        target_cols (list): Columns to predict\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (X, y, feature_cols) - Features and targets for LSTM training\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Creating sliding windows (sequence length: {sequence_length})...\")\n",
    "    \n",
    "    # Select feature columns (exclude time and target columns)\n",
    "    feature_cols = [col for col in data.columns if col not in ['Open time', 'Close time'] + target_cols]\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    data_clean = data.dropna()\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(sequence_length, len(data_clean)):\n",
    "        # Input: sequence_length previous candles\n",
    "        X.append(data_clean[feature_cols].iloc[i-sequence_length:i].values)\n",
    "        \n",
    "        # Target: next candle's OHLCV values\n",
    "        y.append(data_clean[target_cols].iloc[i].values)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(f\"‚úÖ Sliding windows created!\")\n",
    "    print(f\"üìä X shape: {X.shape} (samples, sequence_length, features)\")\n",
    "    print(f\"üìä y shape: {y.shape} (samples, targets)\")\n",
    "    \n",
    "    return X, y, feature_cols\n",
    "\n",
    "\n",
    "def preprocess_data_for_lstm(df, test_size=TEST_SIZE):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for LSTM training.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with OHLCV data\n",
    "        test_size (float): Proportion of data to use for testing\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, y_train, y_test, feature_cols)\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting LSTM prediction preprocessing...\")\n",
    "    \n",
    "    # Step 1: Create time series features\n",
    "    data_with_features = create_time_series_features(df, LAG_PERIOD)\n",
    "    \n",
    "    # Step 2: Create sliding windows\n",
    "    X, y, feature_cols = create_sliding_windows(data_with_features, SEQUENCE_LENGTH)\n",
    "    \n",
    "    # Step 3: Split data\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    \n",
    "    X_train = X[:split_index]\n",
    "    X_test = X[split_index:]\n",
    "    y_train = y[:split_index]\n",
    "    y_test = y[split_index:]\n",
    "    \n",
    "    print(f\"‚úÇÔ∏è Data split completed!\")\n",
    "    print(f\"üìä Training samples: {X_train.shape[0]}\")\n",
    "    print(f\"üìä Test samples: {X_test.shape[0]}\")\n",
    "    print(f\"üìä Sequence length: {X_train.shape[1]}\")\n",
    "    print(f\"üìä Features per timestep: {X_train.shape[2]}\")\n",
    "    print(f\"üìä Target variables: {y_train.shape[1]}\")\n",
    "    \n",
    "    # Show data structure\n",
    "    print(f\"\\nüìä DATA STRUCTURE DEMONSTRATION:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\nüîç Sample 1:\")\n",
    "    print(f\"   Input: {X_train.shape[1]} previous candles ‚Üí Predict next candle\")\n",
    "    print(f\"   Features per candle: {X_train.shape[2]}\")\n",
    "    print(f\"   Target: {y_train.shape[1]} OHLCV values\")\n",
    "    \n",
    "    # Show the last candle's features\n",
    "    last_candle_features = X_train[0, -1, :]  # Last timestep of first sample\n",
    "    print(f\"\\n   Last candle features (first 10):\")\n",
    "    for j in range(min(10, len(feature_cols))):\n",
    "        print(f\"     {feature_cols[j]}: {last_candle_features[j]:.4f}\")\n",
    "    if len(feature_cols) > 10:\n",
    "        print(f\"     ... and {len(feature_cols) - 10} more features\")\n",
    "    \n",
    "    # Show target\n",
    "    print(f\"\\n   Target (next candle OHLCV):\")\n",
    "    target_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    for j, target in enumerate(target_cols):\n",
    "        print(f\"     {target}: {y_train[0, j]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìà This means:\")\n",
    "    print(f\"   - Each training sample uses {X_train.shape[1]} consecutive candles\")\n",
    "    print(f\"   - Each candle has {X_train.shape[2]} features\")\n",
    "    print(f\"   - Model predicts the next candle's {y_train.shape[1]} values\")\n",
    "    print(f\"   - Total training samples: {X_train.shape[0]}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, feature_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_time_series_data(X_train, X_test, y_train, y_test, feature_cols):\n",
    "    \"\"\"\n",
    "    Scale the time series data for LSTM training.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test: Training and test features (samples, timesteps, features)\n",
    "        y_train, y_test: Training and test targets\n",
    "        feature_cols: List of feature column names\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_X, scaler_y)\n",
    "    \"\"\"\n",
    "    print(\"üî¢ Scaling time series data...\")\n",
    "    \n",
    "    # Reshape for scaling (samples * timesteps, features)\n",
    "    X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "    X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_X = MinMaxScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train_reshaped)\n",
    "    X_test_scaled = scaler_X.transform(X_test_reshaped)\n",
    "    \n",
    "    # Reshape back to (samples, timesteps, features)\n",
    "    X_train_scaled = X_train_scaled.reshape(X_train.shape)\n",
    "    X_test_scaled = X_test_scaled.reshape(X_test.shape)\n",
    "    \n",
    "    # Scale targets\n",
    "    scaler_y = MinMaxScaler()\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    y_test_scaled = scaler_y.transform(y_test)\n",
    "    \n",
    "    print(\"‚úÖ Scaling completed!\")\n",
    "    print(f\"üìä Scaled X_train shape: {X_train_scaled.shape}\")\n",
    "    print(f\"üìä Scaled y_train shape: {y_train_scaled.shape}\")\n",
    "    \n",
    "    # Show scaled data examples\n",
    "    print(f\"\\nüìä SCALED DATA EXAMPLES:\")\n",
    "    print(f\"   First sample, last candle features (first 10):\")\n",
    "    for j in range(min(10, len(feature_cols))):\n",
    "        print(f\"     {feature_cols[j]}: {X_train_scaled[0, -1, j]:.4f}\")\n",
    "    \n",
    "    print(f\"   First sample target (OHLCV):\")\n",
    "    target_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    for j, target in enumerate(target_cols):\n",
    "        print(f\"     {target}: {y_train_scaled[0, j]:.4f}\")\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_X, scaler_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting LSTM prediction preprocessing...\n",
      "üîß Creating time series features...\n",
      "‚è∞ Adding time-based features...\n",
      "üí∞ Adding price-based features...\n",
      "üìä Creating lag features (lag period: 5)...\n",
      "‚úÖ Time series features created! Shape: (8928, 49)\n",
      "\n",
      "‚è∞ Time Feature Examples:\n",
      "   Hour range: 0-23\n",
      "   5-min interval range: 0-287\n",
      "   Interval_sin range: -1.000 to 1.000\n",
      "   Interval_cos range: -1.000 to 1.000\n",
      "üîÑ Creating sliding windows (sequence length: 10)...\n",
      "‚úÖ Sliding windows created!\n",
      "üìä X shape: (8909, 10, 42) (samples, sequence_length, features)\n",
      "üìä y shape: (8909, 5) (samples, targets)\n",
      "‚úÇÔ∏è Data split completed!\n",
      "üìä Training samples: 7127\n",
      "üìä Test samples: 1782\n",
      "üìä Sequence length: 10\n",
      "üìä Features per timestep: 42\n",
      "üìä Target variables: 5\n",
      "\n",
      "üìä DATA STRUCTURE DEMONSTRATION:\n",
      "==================================================\n",
      "\n",
      "üîç Sample 1:\n",
      "   Input: 10 previous candles ‚Üí Predict next candle\n",
      "   Features per candle: 42\n",
      "   Target: 5 OHLCV values\n",
      "\n",
      "   Last candle features (first 10):\n",
      "     Quote asset volume: 14853888.4565\n",
      "     Number of trades: 9641.0000\n",
      "     Taker buy base asset volume: 277.2814\n",
      "     Taker buy quote asset volume: 8152632.9124\n",
      "     Ignore: 0.0000\n",
      "     Hour: 1.0000\n",
      "     Minute: 30.0000\n",
      "     Interval_5min: 18.0000\n",
      "     Interval_sin: 0.3827\n",
      "     Interval_cos: 0.9239\n",
      "     ... and 32 more features\n",
      "\n",
      "   Target (next candle OHLCV):\n",
      "     Open: 29361.7700\n",
      "     High: 29470.0000\n",
      "     Low: 29340.0000\n",
      "     Close: 29400.0100\n",
      "     Volume: 494.4106\n",
      "\n",
      "üìà This means:\n",
      "   - Each training sample uses 10 consecutive candles\n",
      "   - Each candle has 42 features\n",
      "   - Model predicts the next candle's 5 values\n",
      "   - Total training samples: 7127\n",
      "‚úÖ Data preprocessing completed successfully!\n",
      "\n",
      "üìä PROCESSED DATA TABLES:\n",
      "==================================================\n",
      "\n",
      "üìã Training Features (First 10 samples, last candle):\n",
      "   Shape: (7127, 10, 42)\n",
      "   First 10 samples, last candle features (first 10):\n",
      "     Sample 1: [1.48538885e+07 9.64100000e+03 2.77281426e+02 8.15263291e+06\n",
      " 0.00000000e+00 1.00000000e+00 3.00000000e+01 1.80000000e+01\n",
      " 3.82683432e-01 9.23879533e-01]\n",
      "     Sample 2: [1.45480534e+07 8.71600000e+03 3.13759025e+02 9.23376460e+06\n",
      " 0.00000000e+00 1.00000000e+00 3.50000000e+01 1.90000000e+01\n",
      " 4.02746690e-01 9.15311479e-01]\n",
      "     Sample 3: [9.80803062e+06 6.91600000e+03 1.28887871e+02 3.78505368e+06\n",
      " 0.00000000e+00 1.00000000e+00 4.00000000e+01 2.00000000e+01\n",
      " 4.22618262e-01 9.06307787e-01]\n",
      "     Sample 4: [6.99113384e+06 5.50700000e+03 1.48761494e+02 4.36624246e+06\n",
      " 0.00000000e+00 1.00000000e+00 4.50000000e+01 2.10000000e+01\n",
      " 4.42288690e-01 8.96872742e-01]\n",
      "     Sample 5: [5.73524041e+06 6.02000000e+03 1.00480012e+02 2.95052394e+06\n",
      " 0.00000000e+00 1.00000000e+00 5.00000000e+01 2.20000000e+01\n",
      " 4.61748613e-01 8.87010833e-01]\n",
      "     Sample 6: [5.48891913e+06 4.81700000e+03 1.03596697e+02 3.04556350e+06\n",
      " 0.00000000e+00 1.00000000e+00 5.50000000e+01 2.30000000e+01\n",
      " 4.80988769e-01 8.76726756e-01]\n",
      "     Sample 7: [9.13104196e+06 5.78600000e+03 1.50624162e+02 4.43120297e+06\n",
      " 0.00000000e+00 2.00000000e+00 0.00000000e+00 2.40000000e+01\n",
      " 5.00000000e-01 8.66025404e-01]\n",
      "     Sample 8: [4.85299726e+06 3.83800000e+03 7.94999910e+01 2.33409832e+06\n",
      " 0.00000000e+00 2.00000000e+00 5.00000000e+00 2.50000000e+01\n",
      " 5.18773258e-01 8.54911871e-01]\n",
      "     Sample 9: [7.79154060e+06 6.57600000e+03 1.20158839e+02 3.51953245e+06\n",
      " 0.00000000e+00 2.00000000e+00 1.00000000e+01 2.60000000e+01\n",
      " 5.37299608e-01 8.43391446e-01]\n",
      "     Sample 10: [5.51720301e+06 4.60200000e+03 1.22860833e+02 3.59944985e+06\n",
      " 0.00000000e+00 2.00000000e+00 1.50000000e+01 2.70000000e+01\n",
      " 5.55570233e-01 8.31469612e-01]\n",
      "\n",
      "üìã Test Features (First 10 samples, last candle):\n",
      "   Shape: (1782, 10, 42)\n",
      "   First 10 samples, last candle features (first 10):\n",
      "     Sample 1: [ 4.81467026e+06  4.24100000e+03  8.37744070e+01  2.82179061e+06\n",
      "  0.00000000e+00  1.90000000e+01  2.50000000e+01  2.33000000e+02\n",
      " -9.32007869e-01  3.62438038e-01]\n",
      "     Sample 2: [ 7.06547407e+06  4.56400000e+03  9.25686390e+01  3.11443751e+06\n",
      "  0.00000000e+00  1.90000000e+01  3.00000000e+01  2.34000000e+02\n",
      " -9.23879533e-01  3.82683432e-01]\n",
      "     Sample 3: [ 9.45558100e+06  5.71100000e+03  9.42178580e+01  3.16422598e+06\n",
      "  0.00000000e+00  1.90000000e+01  3.50000000e+01  2.35000000e+02\n",
      " -9.15311479e-01  4.02746690e-01]\n",
      "     Sample 4: [ 4.31662348e+06  3.61600000e+03  7.19366280e+01  2.42084630e+06\n",
      "  0.00000000e+00  1.90000000e+01  4.00000000e+01  2.36000000e+02\n",
      " -9.06307787e-01  4.22618262e-01]\n",
      "     Sample 5: [ 3.29294846e+06  2.78100000e+03  5.03077160e+01  1.69509681e+06\n",
      "  0.00000000e+00  1.90000000e+01  4.50000000e+01  2.37000000e+02\n",
      " -8.96872742e-01  4.42288690e-01]\n",
      "     Sample 6: [ 4.65513246e+06  3.05700000e+03  8.84698760e+01  2.97711228e+06\n",
      "  0.00000000e+00  1.90000000e+01  5.00000000e+01  2.38000000e+02\n",
      " -8.87010833e-01  4.61748613e-01]\n",
      "     Sample 7: [ 1.72303586e+07  8.53500000e+03  1.74452280e+02  5.84626905e+06\n",
      "  0.00000000e+00  1.90000000e+01  5.50000000e+01  2.39000000e+02\n",
      " -8.76726756e-01  4.80988769e-01]\n",
      "     Sample 8: [ 2.27582931e+07  1.23070000e+04  2.76128628e+02  9.19908916e+06\n",
      "  0.00000000e+00  2.00000000e+01  0.00000000e+00  2.40000000e+02\n",
      " -8.66025404e-01  5.00000000e-01]\n",
      "     Sample 9: [ 1.60142236e+07  9.38400000e+03  1.74251410e+02  5.78494717e+06\n",
      "  0.00000000e+00  2.00000000e+01  5.00000000e+00  2.41000000e+02\n",
      " -8.54911871e-01  5.18773258e-01]\n",
      "     Sample 10: [ 1.54314572e+07  9.24600000e+03  2.36522482e+02  7.84262764e+06\n",
      "  0.00000000e+00  2.00000000e+01  1.00000000e+01  2.42000000e+02\n",
      " -8.43391446e-01  5.37299608e-01]\n",
      "\n",
      "üìã Training Targets (First 10 samples):\n",
      "   Shape: (7127, 5)\n",
      "   First 10 samples targets (OHLCV):\n",
      "     Sample 1: [29361.77     29470.       29340.       29400.01       494.410646]\n",
      "     Sample 2: [29401.66     29415.8      29312.17     29319.87       334.005053]\n",
      "     Sample 3: [29320.7      29394.23     29311.75     29389.47       238.197783]\n",
      "     Sample 4: [29389.48     29394.46     29338.96     29371.22       195.309364]\n",
      "     Sample 5: [29371.23     29430.85     29352.26     29409.99       186.720557]\n",
      "     Sample 6: [29410.       29465.26     29359.99     29382.73       310.385444]\n",
      "     Sample 7: [29382.73     29386.95     29335.       29375.07       165.302054]\n",
      "     Sample 8: [29375.08     29377.85     29201.78     29248.69       266.004274]\n",
      "     Sample 9: [29248.69     29333.       29240.41     29333.         188.312749]\n",
      "     Sample 10: [29333.       29388.22     29305.01     29362.3        139.327516]\n",
      "\n",
      "üìã Test Targets (First 10 samples):\n",
      "   Shape: (1782, 5)\n",
      "   First 10 samples targets (OHLCV):\n",
      "     Sample 1: [33699.46     33757.68     33570.       33600.22       209.996832]\n",
      "     Sample 2: [33600.23     33679.89     33500.       33651.09       281.774502]\n",
      "     Sample 3: [33651.09     33725.       33577.34     33668.72       128.278728]\n",
      "     Sample 4: [33668.73     33726.61     33664.95     33680.          97.727715]\n",
      "     Sample 5: [33679.99     33707.1      33608.99     33640.8        138.334427]\n",
      "     Sample 6: [33640.8      33655.41     33373.92     33411.54       514.355564]\n",
      "     Sample 7: [33411.54     33421.03     33205.44     33256.26       683.171256]\n",
      "     Sample 8: [33256.26     33313.85     33088.       33151.15       482.466114]\n",
      "     Sample 9: [33151.15     33264.49     33061.12     33150.         465.442653]\n",
      "     Sample 10: [33150.01     33345.57     33115.62     33307.65       361.652063]\n",
      "\n",
      "üìä Data Shapes Summary:\n",
      "Training features: (7127, 10, 42) (samples, sequence_length, features)\n",
      "Test features: (1782, 10, 42) (samples, sequence_length, features)\n",
      "Training targets: (7127, 5) (samples, targets)\n",
      "Test targets: (1782, 5) (samples, targets)\n",
      "\n",
      "üìä Feature Information:\n",
      "   Total features: 42\n",
      "   Feature names (first 10): ['Quote asset volume', 'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume', 'Ignore', 'Hour', 'Minute', 'Interval_5min', 'Interval_sin', 'Interval_cos']\n",
      "   Target variables: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "\n",
      "üìä Data Range Information:\n",
      "   X_train min: -965.6400, max: 149681634.7761\n",
      "   y_train min: 0.0000, max: 41950.0000\n",
      "   X_test min: -1220.8800, max: 174859111.1828\n",
      "   y_test min: 75.4049, max: 38531.9000\n"
     ]
    }
   ],
   "source": [
    "if btc_data is not None:\n",
    "    X_train, X_test, y_train, y_test, feature_cols = preprocess_data_for_lstm(btc_data)\n",
    "    print(\"‚úÖ Data preprocessing completed successfully!\")\n",
    "    \n",
    "    # Show processed data tables\n",
    "    print(\"\\nüìä PROCESSED DATA TABLES:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüìã Training Features (First 10 samples, last candle):\")\n",
    "    print(\"   Shape:\", X_train.shape)\n",
    "    print(\"   First 10 samples, last candle features (first 10):\")\n",
    "    for i in range(min(10, len(X_train))):\n",
    "        print(f\"     Sample {i+1}: {X_train[i, -1, :10]}\")\n",
    "    \n",
    "    print(\"\\nüìã Test Features (First 10 samples, last candle):\")\n",
    "    print(\"   Shape:\", X_test.shape)\n",
    "    print(\"   First 10 samples, last candle features (first 10):\")\n",
    "    for i in range(min(10, len(X_test))):\n",
    "        print(f\"     Sample {i+1}: {X_test[i, -1, :10]}\")\n",
    "    \n",
    "    print(\"\\nüìã Training Targets (First 10 samples):\")\n",
    "    print(\"   Shape:\", y_train.shape)\n",
    "    print(\"   First 10 samples targets (OHLCV):\")\n",
    "    for i in range(min(10, len(y_train))):\n",
    "        print(f\"     Sample {i+1}: {y_train[i]}\")\n",
    "    \n",
    "    print(\"\\nüìã Test Targets (First 10 samples):\")\n",
    "    print(\"   Shape:\", y_test.shape)\n",
    "    print(\"   First 10 samples targets (OHLCV):\")\n",
    "    for i in range(min(10, len(y_test))):\n",
    "        print(f\"     Sample {i+1}: {y_test[i]}\")\n",
    "    \n",
    "    print(\"\\nüìä Data Shapes Summary:\")\n",
    "    print(f\"Training features: {X_train.shape} (samples, sequence_length, features)\")\n",
    "    print(f\"Test features: {X_test.shape} (samples, sequence_length, features)\")\n",
    "    print(f\"Training targets: {y_train.shape} (samples, targets)\")\n",
    "    print(f\"Test targets: {y_test.shape} (samples, targets)\")\n",
    "    \n",
    "    print(f\"\\nüìä Feature Information:\")\n",
    "    print(f\"   Total features: {len(feature_cols)}\")\n",
    "    print(f\"   Feature names (first 10): {feature_cols[:10]}\")\n",
    "    print(f\"   Target variables: ['Open', 'High', 'Low', 'Close', 'Volume']\")\n",
    "    \n",
    "    print(f\"\\nüìä Data Range Information:\")\n",
    "    print(f\"   X_train min: {X_train.min():.4f}, max: {X_train.max():.4f}\")\n",
    "    print(f\"   y_train min: {y_train.min():.4f}, max: {y_train.max():.4f}\")\n",
    "    print(f\"   X_test min: {X_test.min():.4f}, max: {X_test.max():.4f}\")\n",
    "    print(f\"   y_test min: {y_test.min():.4f}, max: {y_test.max():.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utils module reloaded successfully!\n",
      "‚úÖ scale_data function updated!\n",
      "‚úÖ Original data stored for evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Reload utils module to get updated scale_data function\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Remove utils from cache\n",
    "if 'utils' in sys.modules:\n",
    "    del sys.modules['utils']\n",
    "\n",
    "# Remove individual utils modules\n",
    "for module_name in list(sys.modules.keys()):\n",
    "    if module_name.startswith('utils.'):\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "# Re-import utils\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "# Re-import scale_data\n",
    "from utils import scale_data\n",
    "\n",
    "print('‚úÖ Utils module reloaded successfully!')\n",
    "print('‚úÖ scale_data function updated!')\n",
    "\n",
    "# Store original data before scaling (needed for evaluation)\n",
    "if 'X_train' in locals() and 'X_test' in locals() and 'y_train' in locals() and 'y_test' in locals():\n",
    "    X_train_orig = X_train.copy()\n",
    "    X_test_orig = X_test.copy()\n",
    "    y_train_orig = y_train.copy()\n",
    "    y_test_orig = y_test.copy()\n",
    "    print('‚úÖ Original data stored for evaluation!')\n",
    "else:\n",
    "    print('‚ùå No data available for storing originals')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Scaling data for LSTM training...\n",
      "‚úÖ Data scaling completed!\n",
      "   X_train range: 0.0000 to 1.0000\n",
      "   y_train range: 0.0000 to 1.0000\n",
      "‚úÖ Data scaling completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Scale the data for LSTM training\n",
    "if 'X_train' in locals() and 'X_test' in locals() and 'y_train' in locals() and 'y_test' in locals():\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_X, scaler_y = scale_data(X_train, X_test, y_train, y_test)\n",
    "    print(\"‚úÖ Data scaling completed successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå No data available for scaling. Please run preprocessing first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "This section defines the LSTM model architecture for multi-output time series prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape, output_shape, units=50, dropout_rate=0.2):\n",
    "    \"\"\"\n",
    "    Build and compile an LSTM model for multi-output time series prediction.\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): The shape of the input data (timesteps, num_features)\n",
    "        output_shape (int): The number of output features\n",
    "        units (int): The number of units in the LSTM layer\n",
    "        dropout_rate (float): The dropout rate for regularization\n",
    "    \n",
    "    Returns:\n",
    "        tf.keras.Model: The compiled LSTM model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(units=units, activation='relu', input_shape=input_shape),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(units=output_shape)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model(input_shape, output_shape):\n",
    "    \"\"\"\n",
    "    Create and return a configured LSTM model.\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Input shape for the model\n",
    "        output_shape (int): Number of output features\n",
    "    \n",
    "    Returns:\n",
    "        tf.keras.Model: Compiled LSTM model\n",
    "    \"\"\"\n",
    "    model = build_lstm_model(input_shape, output_shape)\n",
    "    \n",
    "    print(\"LSTM Model Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• DOWNLOADING CRYPTOCURRENCY DATA\n",
      "   Symbol: BTCUSDT\n",
      "   Interval: 5m\n",
      "   Date range: 2021 01 to 2021 01\n",
      "   Max rows: 50,000\n",
      "==================================================\n",
      "üìÖ Date range: 2021 months 1 to 1\n",
      "üìä Will download months: ['01']\n",
      "üîÑ Loading data with memory efficiency (max 50,000 rows)...\n",
      "üì• Downloading BTCUSDT 5m data for 2021-01 from Binance Vision...\n",
      "‚úÖ Downloaded 8928 rows for 2021-01\n",
      "   Total rows: 8,928\n",
      "‚úÖ Data loading completed!\n",
      "   Final shape: (8928, 12)\n",
      "\\n‚úÖ Download completed successfully!\n",
      "üìä Final data shape: (8928, 12)\n",
      "üìÖ Date range: 2021-01-01 00:00:00 to 2021-01-31 23:55:00\n",
      "üíæ Memory usage: 0.8 MB\n",
      "\\nüìã Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close time</th>\n",
       "      <th>Quote asset volume</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Taker buy base asset volume</th>\n",
       "      <th>Taker buy quote asset volume</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>28923.63</td>\n",
       "      <td>29017.50</td>\n",
       "      <td>28913.12</td>\n",
       "      <td>28975.65</td>\n",
       "      <td>182.889878</td>\n",
       "      <td>2021-01-01 00:04:59.999</td>\n",
       "      <td>5.300787e+06</td>\n",
       "      <td>5614</td>\n",
       "      <td>80.029129</td>\n",
       "      <td>2.319247e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:05:00</td>\n",
       "      <td>28975.65</td>\n",
       "      <td>28979.53</td>\n",
       "      <td>28846.28</td>\n",
       "      <td>28858.94</td>\n",
       "      <td>214.568104</td>\n",
       "      <td>2021-01-01 00:09:59.999</td>\n",
       "      <td>6.201532e+06</td>\n",
       "      <td>4928</td>\n",
       "      <td>113.761331</td>\n",
       "      <td>3.287213e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 00:10:00</td>\n",
       "      <td>28858.94</td>\n",
       "      <td>28883.20</td>\n",
       "      <td>28690.17</td>\n",
       "      <td>28752.80</td>\n",
       "      <td>442.619587</td>\n",
       "      <td>2021-01-01 00:14:59.999</td>\n",
       "      <td>1.273741e+07</td>\n",
       "      <td>8776</td>\n",
       "      <td>199.913764</td>\n",
       "      <td>5.753595e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 00:15:00</td>\n",
       "      <td>28752.80</td>\n",
       "      <td>28852.48</td>\n",
       "      <td>28720.91</td>\n",
       "      <td>28820.72</td>\n",
       "      <td>174.839779</td>\n",
       "      <td>2021-01-01 00:19:59.999</td>\n",
       "      <td>5.034871e+06</td>\n",
       "      <td>5208</td>\n",
       "      <td>91.542596</td>\n",
       "      <td>2.635936e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 00:20:00</td>\n",
       "      <td>28822.17</td>\n",
       "      <td>28846.46</td>\n",
       "      <td>28744.09</td>\n",
       "      <td>28846.46</td>\n",
       "      <td>161.316784</td>\n",
       "      <td>2021-01-01 00:24:59.999</td>\n",
       "      <td>4.645146e+06</td>\n",
       "      <td>4630</td>\n",
       "      <td>78.111722</td>\n",
       "      <td>2.249406e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open time      Open      High       Low     Close      Volume  \\\n",
       "0 2021-01-01 00:00:00  28923.63  29017.50  28913.12  28975.65  182.889878   \n",
       "1 2021-01-01 00:05:00  28975.65  28979.53  28846.28  28858.94  214.568104   \n",
       "2 2021-01-01 00:10:00  28858.94  28883.20  28690.17  28752.80  442.619587   \n",
       "3 2021-01-01 00:15:00  28752.80  28852.48  28720.91  28820.72  174.839779   \n",
       "4 2021-01-01 00:20:00  28822.17  28846.46  28744.09  28846.46  161.316784   \n",
       "\n",
       "               Close time  Quote asset volume  Number of trades  \\\n",
       "0 2021-01-01 00:04:59.999        5.300787e+06              5614   \n",
       "1 2021-01-01 00:09:59.999        6.201532e+06              4928   \n",
       "2 2021-01-01 00:14:59.999        1.273741e+07              8776   \n",
       "3 2021-01-01 00:19:59.999        5.034871e+06              5208   \n",
       "4 2021-01-01 00:24:59.999        4.645146e+06              4630   \n",
       "\n",
       "   Taker buy base asset volume  Taker buy quote asset volume  Ignore  \n",
       "0                    80.029129                  2.319247e+06       0  \n",
       "1                   113.761331                  3.287213e+06       0  \n",
       "2                   199.913764                  5.753595e+06       0  \n",
       "3                    91.542596                  2.635936e+06       0  \n",
       "4                    78.111722                  2.249406e+06       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Bitcoin data using common download function\n",
    "btc_data = download_crypto_data(\n",
    "    symbol=SYMBOL,\n",
    "    interval=INTERVAL, \n",
    "    data_from=DATA_FROM,\n",
    "    data_to=DATA_TO,\n",
    "    max_rows=50000,  # Limit for memory efficiency\n",
    "    # Uses Binance Vision only\n",
    ")\n",
    "\n",
    "if btc_data is not None and not btc_data.empty:\n",
    "    print(f\"\\\\nüìã Sample Data:\")\n",
    "    display(btc_data.head())\n",
    "else:\n",
    "    print(\"‚ùå No data available for processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model Architecture:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parteekmalik/github/pytorch/crypto_env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,600</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             ‚îÇ        \u001b[38;5;34m18,600\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              ‚îÇ           \u001b[38;5;34m255\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,855</span> (73.65 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,855\u001b[0m (73.65 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,855</span> (73.65 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,855\u001b[0m (73.65 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully!\n"
     ]
    }
   ],
   "source": [
    "if 'X_train' in locals() and 'y_train' in locals():\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    output_shape = y_train.shape[1]\n",
    "    \n",
    "    model = create_model(input_shape, output_shape)\n",
    "    print(\"Model created successfully!\")\n",
    "else:\n",
    "    print(\"Training data not available. Please run preprocessing first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "This section handles model training, evaluation, and visualization of results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=50, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train the LSTM model and return training history.\n",
    "    \n",
    "    Args:\n",
    "        model: The LSTM model to train\n",
    "        X_train: Training features\n",
    "        y_train: Training targets\n",
    "        X_test: Test features\n",
    "        y_test: Test targets\n",
    "        epochs: Number of training epochs\n",
    "        batch_size: Batch size for training\n",
    "    \n",
    "    Returns:\n",
    "        tf.keras.callbacks.History: Training history\n",
    "    \"\"\"\n",
    "    print(\"Starting model training...\")\n",
    "    \n",
    "    # Clean data to remove any infinite values\n",
    "    train_mask = np.all(np.isfinite(X_train), axis=(1, 2)) & np.all(np.isfinite(y_train), axis=1)\n",
    "    test_mask = np.all(np.isfinite(X_test), axis=(1, 2)) & np.all(np.isfinite(y_test), axis=1)\n",
    "    \n",
    "    X_train_clean = X_train[train_mask]\n",
    "    y_train_clean = y_train[train_mask]\n",
    "    X_test_clean = X_test[test_mask]\n",
    "    y_test_clean = y_test[test_mask]\n",
    "    \n",
    "    print(f\"Training on {len(X_train_clean)} samples\")\n",
    "    print(f\"Testing on {len(X_test_clean)} samples\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_clean, y_train_clean,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss = model.evaluate(X_test_clean, y_test_clean, verbose=0)\n",
    "    print(f\"Test Loss: {test_loss[0]:.6f}\")\n",
    "    print(f\"Test MAE: {test_loss[1]:.6f}\")\n",
    "    \n",
    "    return history, X_test_clean, y_test_clean\n",
    "\n",
    "\n",
    "def evaluate_model_performance(model, X_test, y_test, scaler_y, y_test_orig):\n",
    "    \"\"\"\n",
    "    Evaluate model performance and create visualizations.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LSTM model\n",
    "        X_test: Test features\n",
    "        y_test: Test targets (scaled)\n",
    "        scaler_y: Target scaler for inverse transformation\n",
    "        y_test_orig: Original test targets (unscaled)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Performance metrics\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    predictions_scaled = model.predict(X_test)\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled)\n",
    "    y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "    \n",
    "    # Calculate MSE for each target\n",
    "    target_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    mse_scores = {}\n",
    "    \n",
    "    print(\"Model Performance (MSE):\")\n",
    "    for i, col in enumerate(target_columns):\n",
    "        mse = mean_squared_error(y_test_actual[:, i], predictions[:, i])\n",
    "        mse_scores[col] = mse\n",
    "        print(f\"{col}: {mse:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'actual': y_test_actual,\n",
    "        'mse_scores': mse_scores,\n",
    "        'target_columns': target_columns\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss.\n",
    "    \n",
    "    Args:\n",
    "        history: Training history from model.fit()\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title('Model MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_predictions_vs_actual(predictions, actual, target_columns, max_samples=1000):\n",
    "    \"\"\"\n",
    "    Plot predictions vs actual values for each target.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted values\n",
    "        actual: Actual values\n",
    "        target_columns: List of target column names\n",
    "        max_samples: Maximum number of samples to plot\n",
    "    \"\"\"\n",
    "    n_samples = min(len(predictions), max_samples)\n",
    "    \n",
    "    fig, axes = plt.subplots(len(target_columns), 1, figsize=(15, 3 * len(target_columns)))\n",
    "    if len(target_columns) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(target_columns):\n",
    "        axes[i].plot(actual[:n_samples, i], label=f'Actual {col}', alpha=0.7)\n",
    "        axes[i].plot(predictions[:n_samples, i], label=f'Predicted {col}', alpha=0.7)\n",
    "        axes[i].set_title(f'{col} - Actual vs Predicted')\n",
    "        axes[i].set_xlabel('Time Steps')\n",
    "        axes[i].set_ylabel(col)\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Training on 7127 samples\n",
      "Testing on 1782 samples\n",
      "Epoch 1/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 12591449505792.0000 - mae: 1981926.8750 - val_loss: 130328846336.0000 - val_mae: 231178.2969\n",
      "Epoch 2/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298032005120.0000 - mae: 345150.5000 - val_loss: 25019254784.0000 - val_mae: 94668.2500\n",
      "Epoch 3/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78233419776.0000 - mae: 168488.4062 - val_loss: 13119712256.0000 - val_mae: 67017.8203\n",
      "Epoch 4/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43554291712.0000 - mae: 123738.8125 - val_loss: 8967336960.0000 - val_mae: 55872.8516\n",
      "Epoch 5/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26240286720.0000 - mae: 94956.4844 - val_loss: 6327015424.0000 - val_mae: 46162.3203\n",
      "Epoch 6/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18007062528.0000 - mae: 77282.3359 - val_loss: 4640292352.0000 - val_mae: 39190.1953\n",
      "Epoch 7/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14479517696.0000 - mae: 63734.9570 - val_loss: 3379912704.0000 - val_mae: 34193.2227\n",
      "Epoch 8/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8829776896.0000 - mae: 52455.9258 - val_loss: 2719876864.0000 - val_mae: 32662.7578\n",
      "Epoch 9/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6533423104.0000 - mae: 45416.1133 - val_loss: 2133065856.0000 - val_mae: 29344.6250\n",
      "Epoch 10/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5232348160.0000 - mae: 40494.5664 - val_loss: 1736230144.0000 - val_mae: 26900.2168\n",
      "Epoch 11/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6573832704.0000 - mae: 37630.8203 - val_loss: 1483011200.0000 - val_mae: 25651.1250\n",
      "Epoch 12/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3481432832.0000 - mae: 33482.6641 - val_loss: 1311480960.0000 - val_mae: 24297.2910\n",
      "Epoch 13/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5774998016.0000 - mae: 31506.9453 - val_loss: 1174454528.0000 - val_mae: 24499.2070\n",
      "Epoch 14/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7023197696.0000 - mae: 31547.4629 - val_loss: 983238656.0000 - val_mae: 21305.9629\n",
      "Epoch 15/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2405563392.0000 - mae: 28634.9746 - val_loss: 910885696.0000 - val_mae: 22250.2266\n",
      "Epoch 16/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2014388096.0000 - mae: 27282.5195 - val_loss: 820093696.0000 - val_mae: 21133.7695\n",
      "Epoch 17/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1659744640.0000 - mae: 25145.5547 - val_loss: 768290752.0000 - val_mae: 20839.2266\n",
      "Epoch 18/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1465686656.0000 - mae: 24536.1289 - val_loss: 679388352.0000 - val_mae: 18921.6270\n",
      "Epoch 19/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1350591232.0000 - mae: 23556.5078 - val_loss: 652636160.0000 - val_mae: 19236.1406\n",
      "Epoch 20/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1186476288.0000 - mae: 22427.8379 - val_loss: 707649728.0000 - val_mae: 21111.3691\n",
      "Epoch 21/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1017086080.0000 - mae: 21817.8789 - val_loss: 579686784.0000 - val_mae: 18496.0879\n",
      "Epoch 22/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1049536832.0000 - mae: 21683.8711 - val_loss: 609161088.0000 - val_mae: 19294.1172\n",
      "Epoch 23/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1089744256.0000 - mae: 21830.9473 - val_loss: 503141760.0000 - val_mae: 17153.8047\n",
      "Epoch 24/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 932492480.0000 - mae: 21335.5508 - val_loss: 486131488.0000 - val_mae: 17927.6836\n",
      "Epoch 25/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 839582592.0000 - mae: 20308.8320 - val_loss: 426262272.0000 - val_mae: 16034.8271\n",
      "Epoch 26/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 738809664.0000 - mae: 19420.7363 - val_loss: 485230048.0000 - val_mae: 18141.0391\n",
      "Epoch 27/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 635160384.0000 - mae: 18934.6523 - val_loss: 410679264.0000 - val_mae: 16527.8535\n",
      "Epoch 28/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 652713472.0000 - mae: 18498.6875 - val_loss: 440936832.0000 - val_mae: 17466.9160\n",
      "Epoch 29/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 608254464.0000 - mae: 18547.7402 - val_loss: 368471488.0000 - val_mae: 15788.8135\n",
      "Epoch 30/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 612982720.0000 - mae: 17929.4434 - val_loss: 351000384.0000 - val_mae: 15240.5566\n",
      "Epoch 31/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496266720.0000 - mae: 17009.1777 - val_loss: 376192256.0000 - val_mae: 16157.2178\n",
      "Epoch 32/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 597239552.0000 - mae: 17892.3555 - val_loss: 410341120.0000 - val_mae: 17246.2461\n",
      "Epoch 33/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 555828224.0000 - mae: 17442.2012 - val_loss: 402540896.0000 - val_mae: 16985.3398\n",
      "Epoch 34/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 545290560.0000 - mae: 17594.9082 - val_loss: 331248576.0000 - val_mae: 14941.1992\n",
      "Epoch 35/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 482713952.0000 - mae: 16839.7148 - val_loss: 383577472.0000 - val_mae: 16418.9082\n",
      "Epoch 36/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 495688448.0000 - mae: 17037.5527 - val_loss: 390333568.0000 - val_mae: 16785.1484\n",
      "Epoch 37/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 525193536.0000 - mae: 17319.7207 - val_loss: 414346496.0000 - val_mae: 17463.6191\n",
      "Epoch 38/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 504655104.0000 - mae: 17121.0762 - val_loss: 300066528.0000 - val_mae: 14189.3799\n",
      "Epoch 39/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496971680.0000 - mae: 17004.3203 - val_loss: 348728288.0000 - val_mae: 15677.0645\n",
      "Epoch 40/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 440970592.0000 - mae: 15986.0605 - val_loss: 388059328.0000 - val_mae: 16940.8887\n",
      "Epoch 41/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461027712.0000 - mae: 16467.7930 - val_loss: 282061344.0000 - val_mae: 13519.0264\n",
      "Epoch 42/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 439450176.0000 - mae: 15951.1211 - val_loss: 286992224.0000 - val_mae: 13804.7695\n",
      "Epoch 43/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425673088.0000 - mae: 15709.9414 - val_loss: 281598368.0000 - val_mae: 13641.6270\n",
      "Epoch 44/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441730752.0000 - mae: 15840.7617 - val_loss: 331752416.0000 - val_mae: 15305.8789\n",
      "Epoch 45/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 414472992.0000 - mae: 15780.9170 - val_loss: 500237312.0000 - val_mae: 19583.1152\n",
      "Epoch 46/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 553855296.0000 - mae: 18067.4434 - val_loss: 349661056.0000 - val_mae: 15995.2773\n",
      "Epoch 47/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451087648.0000 - mae: 16377.6973 - val_loss: 332757856.0000 - val_mae: 15288.2705\n",
      "Epoch 48/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480081120.0000 - mae: 16426.3730 - val_loss: 342448640.0000 - val_mae: 15613.9219\n",
      "Epoch 49/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433471776.0000 - mae: 16031.0928 - val_loss: 313127136.0000 - val_mae: 14930.7900\n",
      "Epoch 50/50\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464639840.0000 - mae: 16132.9570 - val_loss: 273344352.0000 - val_mae: 13251.5508\n",
      "Test Loss: 425947744.000000\n",
      "Test MAE: 13300.023438\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/lt9sypd93_n_lrjkf947dr4r0000gn/T/ipykernel_44436/707195102.py:113: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance (MSE):\n",
      "Open: 90290782066773344.0000\n",
      "High: 91531056455964416.0000\n",
      "Low: 98205311467716352.0000\n",
      "Close: 88985279148154288.0000\n",
      "Volume: 4515406011860.9834\n",
      "Training and evaluation completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/lt9sypd93_n_lrjkf947dr4r0000gn/T/ipykernel_44436/707195102.py:142: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals() and 'X_train' in locals() and 'y_train' in locals():\n",
    "    history, X_test_clean, y_test_clean = train_model(model, X_train, y_train, X_test, y_test, epochs=50)\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    results = evaluate_model_performance(model, X_test_clean, y_test_clean, scaler_y, y_test_orig)\n",
    "    \n",
    "    # Plot predictions vs actual\n",
    "    plot_predictions_vs_actual(\n",
    "        results['predictions'], \n",
    "        results['actual'], \n",
    "        results['target_columns']\n",
    "    )\n",
    "    \n",
    "    print(\"Training and evaluation completed!\")\n",
    "else:\n",
    "    print(\"Model or training data not available. Please run previous cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Functions\n",
    "\n",
    "This section provides functions to make predictions on new data using the trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_step(model, new_data_df, scaler_X, scaler_y, timesteps=1):\n",
    "    \"\"\"\n",
    "    Make predictions on new data using the trained LSTM model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LSTM model\n",
    "        new_data_df (pd.DataFrame): DataFrame containing historical data for feature calculation\n",
    "        scaler_X: Fitted scaler for input features\n",
    "        scaler_y: Fitted scaler for target variables\n",
    "        timesteps (int): Number of timesteps the LSTM expects\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Predictions for the next time step\n",
    "    \"\"\"\n",
    "    if new_data_df is None or new_data_df.empty:\n",
    "        print(\"Error: No new data provided for prediction.\")\n",
    "        return None\n",
    "    \n",
    "    # Create features using the same preprocessing as training\n",
    "    features_df = create_time_series_features(new_data_df, LAG_PERIOD)\n",
    "    \n",
    "    # Remove original features and time columns (keep only engineered ones)\n",
    "    # Use the same feature selection as in create_sliding_windows function\n",
    "    target_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    feature_cols = [col for col in features_df.columns if col not in ['Open time', 'Close time'] + target_cols]\n",
    "    features_df = features_df[feature_cols]\n",
    "    \n",
    "    # Get the last valid row of features\n",
    "    latest_features = features_df.dropna().iloc[[-1]].copy()\n",
    "    \n",
    "    if latest_features.empty:\n",
    "        print(\"Error: Not enough valid data to calculate features for prediction.\")\n",
    "        return None\n",
    "    \n",
    "    # Scale the features\n",
    "    latest_features_scaled = scaler_X.transform(latest_features)\n",
    "    \n",
    "    # Reshape for LSTM input\n",
    "    latest_features_lstm = latest_features_scaled.reshape((1, timesteps, latest_features_scaled.shape[1]))\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions_scaled = model.predict(latest_features_lstm)\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    target_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    prediction_df = pd.DataFrame(predictions, columns=target_columns)\n",
    "    \n",
    "    return prediction_df\n",
    "\n",
    "\n",
    "def generate_sample_data(original_data, n_samples=100, noise_factor=0.001):\n",
    "    \"\"\"\n",
    "    Generate sample data for testing predictions.\n",
    "    \n",
    "    Args:\n",
    "        original_data: Original DataFrame to use as template\n",
    "        n_samples: Number of samples to generate\n",
    "        noise_factor: Amount of noise to add (as fraction of standard deviation)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Generated sample data\n",
    "    \"\"\"\n",
    "    # Take the last n_samples from original data\n",
    "    sample_data = original_data.tail(n_samples).copy()\n",
    "    \n",
    "    # Add small amount of noise to make it different\n",
    "    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "        noise = np.random.randn(len(sample_data)) * sample_data[col].std() * noise_factor\n",
    "        sample_data[col] = sample_data[col] + noise\n",
    "    \n",
    "    return sample_data\n",
    "\n",
    "\n",
    "def demonstrate_prediction(model, scaler_X, scaler_y, original_data):\n",
    "    \"\"\"\n",
    "    Demonstrate prediction functionality with sample data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LSTM model\n",
    "        scaler_X: Fitted scaler for input features\n",
    "        scaler_y: Fitted scaler for target variables\n",
    "        original_data: Original data to use for generating samples\n",
    "    \"\"\"\n",
    "    print(\"Generating sample data for prediction demonstration...\")\n",
    "    \n",
    "    # Generate sample data\n",
    "    sample_data = generate_sample_data(original_data, n_samples=100)\n",
    "    \n",
    "    print(f\"Sample data shape: {sample_data.shape}\")\n",
    "    print(\"Last 5 rows of sample data:\")\n",
    "    display(sample_data[['Open time', 'Open', 'High', 'Low', 'Close', 'Volume']].tail())\n",
    "    \n",
    "    # Make prediction\n",
    "    print(\"\\nMaking prediction for next time step...\")\n",
    "    prediction = predict_next_step(model, sample_data, scaler_X, scaler_y)\n",
    "    \n",
    "    if prediction is not None:\n",
    "        print(\"Predicted values for next time step:\")\n",
    "        display(prediction)\n",
    "        \n",
    "        # Show the actual next values for comparison (if available)\n",
    "        if len(original_data) > len(sample_data):\n",
    "            actual_next = original_data.iloc[len(sample_data):len(sample_data)+1][['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "            print(\"\\nActual values for comparison:\")\n",
    "            display(actual_next)\n",
    "    else:\n",
    "        print(\"Failed to generate prediction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample data for prediction demonstration...\n",
      "Sample data shape: (100, 12)\n",
      "Last 5 rows of sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>2021-01-31 23:35:00</td>\n",
       "      <td>33121.244011</td>\n",
       "      <td>33168.276217</td>\n",
       "      <td>33105.978159</td>\n",
       "      <td>33136.713236</td>\n",
       "      <td>164.031094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>2021-01-31 23:40:00</td>\n",
       "      <td>33136.688629</td>\n",
       "      <td>33148.468903</td>\n",
       "      <td>33044.412981</td>\n",
       "      <td>33107.598038</td>\n",
       "      <td>250.693841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>2021-01-31 23:45:00</td>\n",
       "      <td>33107.580178</td>\n",
       "      <td>33168.344560</td>\n",
       "      <td>33076.238789</td>\n",
       "      <td>33116.146530</td>\n",
       "      <td>252.164210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>2021-01-31 23:50:00</td>\n",
       "      <td>33116.268592</td>\n",
       "      <td>33186.799520</td>\n",
       "      <td>33058.547155</td>\n",
       "      <td>33187.057873</td>\n",
       "      <td>228.390450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8927</th>\n",
       "      <td>2021-01-31 23:55:00</td>\n",
       "      <td>33187.459751</td>\n",
       "      <td>33238.828544</td>\n",
       "      <td>33049.223936</td>\n",
       "      <td>33092.807953</td>\n",
       "      <td>442.518859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open time          Open          High           Low  \\\n",
       "8923 2021-01-31 23:35:00  33121.244011  33168.276217  33105.978159   \n",
       "8924 2021-01-31 23:40:00  33136.688629  33148.468903  33044.412981   \n",
       "8925 2021-01-31 23:45:00  33107.580178  33168.344560  33076.238789   \n",
       "8926 2021-01-31 23:50:00  33116.268592  33186.799520  33058.547155   \n",
       "8927 2021-01-31 23:55:00  33187.459751  33238.828544  33049.223936   \n",
       "\n",
       "             Close      Volume  \n",
       "8923  33136.713236  164.031094  \n",
       "8924  33107.598038  250.693841  \n",
       "8925  33116.146530  252.164210  \n",
       "8926  33187.057873  228.390450  \n",
       "8927  33092.807953  442.518859  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making prediction for next time step...\n",
      "üîß Creating time series features...\n",
      "‚è∞ Adding time-based features...\n",
      "üí∞ Adding price-based features...\n",
      "üìä Creating lag features (lag period: 5)...\n",
      "‚úÖ Time series features created! Shape: (100, 49)\n",
      "\n",
      "‚è∞ Time Feature Examples:\n",
      "   Hour range: 15-23\n",
      "   5-min interval range: 188-287\n",
      "   Interval_sin range: -1.000 to -0.022\n",
      "   Interval_cos range: -0.574 to 1.000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Predicted values for next time step:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85470.945312</td>\n",
       "      <td>66068.828125</td>\n",
       "      <td>76575.023438</td>\n",
       "      <td>57265.785156</td>\n",
       "      <td>460.133698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open          High           Low         Close      Volume\n",
       "0  85470.945312  66068.828125  76575.023438  57265.785156  460.133698"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual values for comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>28931.48</td>\n",
       "      <td>28999.96</td>\n",
       "      <td>28872.24</td>\n",
       "      <td>28998.77</td>\n",
       "      <td>338.750054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open      High       Low     Close      Volume\n",
       "100  28931.48  28999.96  28872.24  28998.77  338.750054"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate prediction functionality\n",
    "if 'model' in locals() and 'scaler_X' in locals() and 'scaler_y' in locals() and 'btc_data' in locals():\n",
    "    demonstrate_prediction(model, scaler_X, scaler_y, btc_data)\n",
    "else:\n",
    "    print(\"Model, scalers, or data not available. Please run training first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Visualization Functions\n",
    "\n",
    "This section provides additional visualization utilities for analyzing the data and model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_data(df, title=\"Cryptocurrency Price Data\", max_points=2000):\n",
    "    \"\"\"\n",
    "    Plot the original price data.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with OHLCV data\n",
    "        title: Plot title\n",
    "        max_points: Maximum number of points to plot\n",
    "    \"\"\"\n",
    "    n_points = min(len(df), max_points)\n",
    "    data_subset = df.tail(n_points)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Price subplot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(data_subset['Open time'], data_subset['Close'], label='Close Price', alpha=0.8)\n",
    "    plt.title('Close Price Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USDT)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Volume subplot\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(data_subset['Open time'], data_subset['Volume'], label='Volume', color='orange', alpha=0.8)\n",
    "    plt.title('Volume Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Volume')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # OHLC subplot\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(data_subset['Open time'], data_subset['Open'], label='Open', alpha=0.7)\n",
    "    plt.plot(data_subset['Open time'], data_subset['High'], label='High', alpha=0.7)\n",
    "    plt.plot(data_subset['Open time'], data_subset['Low'], label='Low', alpha=0.7)\n",
    "    plt.plot(data_subset['Open time'], data_subset['Close'], label='Close', alpha=0.7)\n",
    "    plt.title('OHLC Prices')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price (USDT)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Price distribution\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(data_subset['Close'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.title('Close Price Distribution')\n",
    "    plt.xlabel('Price (USDT)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_prediction_errors(predictions, actual, target_columns):\n",
    "    \"\"\"\n",
    "    Plot prediction errors for each target variable.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted values\n",
    "        actual: Actual values\n",
    "        target_columns: List of target column names\n",
    "    \"\"\"\n",
    "    errors = actual - predictions\n",
    "    \n",
    "    fig, axes = plt.subplots(len(target_columns), 1, figsize=(15, 3 * len(target_columns)))\n",
    "    if len(target_columns) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, col in enumerate(target_columns):\n",
    "        axes[i].plot(errors[:, i], label=f'Error ({col})', alpha=0.7, color='red')\n",
    "        axes[i].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        axes[i].set_title(f'Prediction Error for {col}')\n",
    "        axes[i].set_xlabel('Time Steps')\n",
    "        axes[i].set_ylabel('Error')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_feature_importance(feature_names, model_weights=None):\n",
    "    \"\"\"\n",
    "    Plot feature importance if available.\n",
    "    \n",
    "    Args:\n",
    "        feature_names: List of feature names\n",
    "        model_weights: Model weights (if available)\n",
    "    \"\"\"\n",
    "    if model_weights is None:\n",
    "        print(\"Feature importance not available for LSTM models.\")\n",
    "        return\n",
    "    \n",
    "    # This is a placeholder - LSTM feature importance is complex\n",
    "    # In practice, you might use permutation importance or SHAP values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(feature_names)), model_weights)\n",
    "    plt.title('Feature Importance (Placeholder)')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.xticks(range(len(feature_names)), feature_names, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_summary_report(results, model_history=None):\n",
    "    \"\"\"\n",
    "    Create a summary report of model performance.\n",
    "    \n",
    "    Args:\n",
    "        results: Results dictionary from evaluate_model_performance\n",
    "        model_history: Training history (optional)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nMSE Scores:\")\n",
    "    for col, mse in results['mse_scores'].items():\n",
    "        print(f\"  {col}: {mse:.4f}\")\n",
    "    \n",
    "    # Calculate overall performance\n",
    "    avg_mse = np.mean(list(results['mse_scores'].values()))\n",
    "    print(f\"\\nAverage MSE: {avg_mse:.4f}\")\n",
    "    \n",
    "    if model_history is not None:\n",
    "        final_train_loss = model_history.history['loss'][-1]\n",
    "        final_val_loss = model_history.history['val_loss'][-1]\n",
    "        print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
    "        print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(\"  - Type: LSTM (Long Short-Term Memory)\")\n",
    "    print(\"  - Input Shape: (timesteps, features)\")\n",
    "    print(\"  - Output: Multi-output regression\")\n",
    "    print(\"  - Targets: Open, High, Low, Close, Volume\")\n",
    "    \n",
    "    print(\"\\nData Information:\")\n",
    "    print(f\"  - Training samples: {len(results['actual'])}\")\n",
    "    print(f\"  - Features per sample: {results['predictions'].shape[1]}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting original price data...\n",
      "\n",
      "Plotting prediction errors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/lt9sypd93_n_lrjkf947dr4r0000gn/T/ipykernel_44436/1204432912.py:58: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/var/folders/t0/lt9sypd93_n_lrjkf947dr4r0000gn/T/ipykernel_44436/1204432912.py:86: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summary report...\n",
      "============================================================\n",
      "MODEL PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "\n",
      "MSE Scores:\n",
      "  Open: 90290782066773344.0000\n",
      "  High: 91531056455964416.0000\n",
      "  Low: 98205311467716352.0000\n",
      "  Close: 88985279148154288.0000\n",
      "  Volume: 4515406011860.9834\n",
      "\n",
      "Average MSE: 73803388908924048.0000\n",
      "\n",
      "Final Training Loss: 451215104.0000\n",
      "Final Validation Loss: 273344352.0000\n",
      "\n",
      "Model Architecture:\n",
      "  - Type: LSTM (Long Short-Term Memory)\n",
      "  - Input Shape: (timesteps, features)\n",
      "  - Output: Multi-output regression\n",
      "  - Targets: Open, High, Low, Close, Volume\n",
      "\n",
      "Data Information:\n",
      "  - Training samples: 1782\n",
      "  - Features per sample: 5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Additional visualizations and analysis\n",
    "if 'btc_data' in locals() and btc_data is not None:\n",
    "    print(\"Plotting original price data...\")\n",
    "    plot_price_data(btc_data, \"Bitcoin Price Data (2021)\")\n",
    "    \n",
    "if 'results' in locals() and results is not None:\n",
    "    print(\"\\nPlotting prediction errors...\")\n",
    "    plot_prediction_errors(results['predictions'], results['actual'], results['target_columns'])\n",
    "    \n",
    "    print(\"\\nGenerating summary report...\")\n",
    "    if 'history' in locals():\n",
    "        create_summary_report(results, history)\n",
    "    else:\n",
    "        create_summary_report(results)\n",
    "else:\n",
    "    print(\"Data or results not available for additional visualizations.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
