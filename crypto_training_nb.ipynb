{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 Crypto Prediction Model Training - New Approach\n",
        "\n",
        "This notebook trains an LSTM model using the **expanded range scaling approach** with OHLC-only data.\n",
        "\n",
        "## Key Features:\n",
        "- **OHLC-only data** (Volume removed)\n",
        "- **Expanded range scaling** with clipping filter\n",
        "- **Independent sequence scaling** for better time series handling\n",
        "- **Combined input+output visualization** for continuous charting\n",
        "- **Updated model architecture** for HLC prediction (Open derived from previous Close)\n",
        "\n",
        "## Approach:\n",
        "1. Load and prepare OHLC data\n",
        "2. Apply expanded range scaling (input min/2 to input max*2)\n",
        "3. Train LSTM model on scaled sequences\n",
        "4. Evaluate and visualize results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Imports and Setup\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from IPython.display import display\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# Configure matplotlib for notebook environment\n",
        "plt.style.use('default')\n",
        "\n",
        "# Import our updated utilities\n",
        "from src import (\n",
        "    BinanceDataOrganizer,\n",
        "    create_lstm_model, evaluate_model, predict_next_candle, add_open_to_predictions,\n",
        "    draw_candlestick_chart, plot_combined_input_output_charts, plot_sample_data_comparison,\n",
        "    plot_training_history, plot_predictions_vs_actual,\n",
        "    production_config, test_config\n",
        ")\n",
        "\n",
        "print(\"✅ Imports successful - New approach ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration Selection\n",
        "\n",
        "Choose between production and test configurations:\n",
        "\n",
        "- **Production Config**: Full-scale deployment with larger models and more data\n",
        "- **Test Config**: Fast execution for development and testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Configuration Selection\n",
        "CONFIG_MODE = 'test'  # Change to 'production' for full-scale deployment\n",
        "\n",
        "if CONFIG_MODE == 'production':\n",
        "    config = production_config\n",
        "    print(\"🚀 PRODUCTION mode\")\n",
        "else:\n",
        "    config = test_config\n",
        "    print(\"⚡ TEST mode\")\n",
        "\n",
        "print(f\"Config: {config.symbol} {config.timeframe} | {config.start_date} to {config.end_date}\")\n",
        "print(f\"Model: {config.lstm_units} units, {config.epochs} epochs, {config.sequence_length}→{config.prediction_length}\")\n",
        "print(f\"Features: OHLC only (Volume removed)\")\n",
        "print(f\"Scaling: Expanded range approach with clipping filter\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Scaling\n",
        "\n",
        "Load cryptocurrency data and apply the new expanded range scaling approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Data Loading and Scaling\n",
        "print(\"📊 LOADING DATA WITH NEW EXPANDED RANGE SCALING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create data organizer\n",
        "organizer = BinanceDataOrganizer(config)\n",
        "\n",
        "# Get unscaled data for analysis\n",
        "unscaled_data = organizer.get_unscaled_split_data()\n",
        "X_train_unscaled = unscaled_data['input_train']\n",
        "y_train_unscaled = unscaled_data['output_train']\n",
        "X_test_unscaled = unscaled_data['input_test']\n",
        "y_test_unscaled = unscaled_data['output_test']\n",
        "\n",
        "print(f\"1️⃣ Unscaled Data Shapes:\")\n",
        "print(f\"   X_train: {X_train_unscaled.shape}\")\n",
        "print(f\"   y_train: {y_train_unscaled.shape}\")\n",
        "print(f\"   X_test: {X_test_unscaled.shape}\")\n",
        "print(f\"   y_test: {y_test_unscaled.shape}\")\n",
        "\n",
        "# Get scaled data using new approach\n",
        "scaled_data = organizer.get_scaled_data()\n",
        "X_train_scaled = scaled_data['input_train_scaled']\n",
        "y_train_scaled = scaled_data['output_train_scaled']\n",
        "X_test_scaled = scaled_data['input_test_scaled']\n",
        "y_test_scaled = scaled_data['output_test_scaled']\n",
        "\n",
        "print(f\"\\n2️⃣ Scaled Data Shapes:\")\n",
        "print(f\"   X_train: {X_train_scaled.shape}\")\n",
        "print(f\"   y_train: {y_train_scaled.shape}\")\n",
        "print(f\"   X_test: {X_test_scaled.shape}\")\n",
        "print(f\"   y_test: {y_test_scaled.shape}\")\n",
        "\n",
        "print(f\"\\n3️⃣ Scaling Ranges:\")\n",
        "print(f\"   X_train range: {X_train_scaled.min():.6f} to {X_train_scaled.max():.6f}\")\n",
        "print(f\"   y_train range: {y_train_scaled.min():.6f} to {y_train_scaled.max():.6f}\")\n",
        "print(f\"   ✅ Both in 0-1 range: {np.all(X_train_scaled >= 0) and np.all(X_train_scaled <= 1)}\")\n",
        "print(f\"   ✅ Both in 0-1 range: {np.all(y_train_scaled >= 0) and np.all(y_train_scaled <= 1)}\")\n",
        "\n",
        "print(f\"\\n✅ Data loading and scaling completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Visualization\n",
        "\n",
        "Visualize the unscaled and scaled data using candlestick charts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Data Visualization\n",
        "print(\"📊 VISUALIZING DATA WITH CANDLESTICK CHARTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Combine first sequence for visualization\n",
        "first_sequence_unscaled = organizer.combine_input_output_for_chart(X_train_unscaled[0], y_train_unscaled[0])\n",
        "first_sequence_scaled = organizer.combine_input_output_for_chart(X_train_scaled[0], y_train_scaled[0])\n",
        "\n",
        "print(f\"📈 Creating candlestick charts for first sequence ({len(first_sequence_unscaled)} timesteps)...\")\n",
        "print(f\"   Input timesteps: {config.sequence_length}\")\n",
        "print(f\"   Output timesteps: {config.prediction_length}\")\n",
        "print(f\"   Total timesteps: {len(first_sequence_unscaled)}\")\n",
        "\n",
        "# Display combined charts\n",
        "plot_combined_input_output_charts(\n",
        "    first_sequence_unscaled, \n",
        "    first_sequence_scaled, \n",
        "    config, \n",
        "    'Training Data Visualization'\n",
        ")\n",
        "\n",
        "# Display sample data comparison\n",
        "plot_sample_data_comparison(\n",
        "    first_sequence_unscaled, \n",
        "    first_sequence_scaled, \n",
        "    config, \n",
        "    num_samples=10\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Data visualization completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Creation and Training\n",
        "\n",
        "Create and train the LSTM model using the new approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Model Creation\n",
        "print(\"🤖 CREATING LSTM MODEL\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Create model with updated architecture\n",
        "input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])  # (sequence_length, features)\n",
        "model = create_lstm_model(\n",
        "    input_shape=input_shape,\n",
        "    lstm_units=config.lstm_units,\n",
        "    dropout_rate=config.dropout_rate,\n",
        "    learning_rate=config.learning_rate,\n",
        "    prediction_length=config.prediction_length\n",
        ")\n",
        "\n",
        "print(f\"✅ Model created successfully!\")\n",
        "print(f\"   Input shape: {input_shape}\")\n",
        "print(f\"   Output size: {config.prediction_length * 3} (HLC per timestep)\")\n",
        "print(f\"   Total parameters: {model.count_params():,}\")\n",
        "print(f\"   Architecture: LSTM → LSTM → Dense → Dense\")\n",
        "\n",
        "# Display model summary\n",
        "print(f\"\\n📋 Model Summary:\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Model Training\n",
        "print(\"🚀 TRAINING LSTM MODEL\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(f\"Training configuration:\")\n",
        "print(f\"   Epochs: {config.epochs}\")\n",
        "print(f\"   Batch size: {config.batch_size}\")\n",
        "print(f\"   Patience: {config.patience}\")\n",
        "print(f\"   Learning rate: {config.learning_rate}\")\n",
        "\n",
        "# Train the model\n",
        "print(f\"\\n🔥 Starting training...\")\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train_scaled,\n",
        "    validation_data=(X_test_scaled, y_test_scaled),\n",
        "    epochs=config.epochs,\n",
        "    batch_size=config.batch_size,\n",
        "    verbose=1,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            patience=config.patience, \n",
        "            restore_best_weights=True,\n",
        "            monitor='val_loss'\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            patience=config.lr_patience, \n",
        "            factor=config.lr_factor, \n",
        "            min_lr=config.min_lr,\n",
        "            monitor='val_loss'\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Training completed successfully!\")\n",
        "print(f\"   Final training loss: {history.history['loss'][-1]:.6f}\")\n",
        "print(f\"   Final validation loss: {history.history['val_loss'][-1]:.6f}\")\n",
        "print(f\"   Final training MAE: {history.history['mae'][-1]:.6f}\")\n",
        "print(f\"   Final validation MAE: {history.history['val_mae'][-1]:.6f}\")\n",
        "\n",
        "# Display training history\n",
        "print(f\"\\n📊 Training History Charts:\")\n",
        "plot_training_history(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation and Testing\n",
        "\n",
        "Evaluate the trained model and test predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Model Evaluation\n",
        "print(\"📊 EVALUATING TRAINED MODEL\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Evaluate on test data\n",
        "print(\"1️⃣ Evaluating on test data...\")\n",
        "test_metrics = evaluate_model(model, X_test_scaled, y_test_scaled)\n",
        "\n",
        "print(f\"Test Results:\")\n",
        "print(f\"   MSE: {test_metrics['test_loss']:.6f}\")\n",
        "print(f\"   MAE: {test_metrics['test_mae']:.6f}\")\n",
        "print(f\"   MAPE: {test_metrics['test_mape']:.2f}%\")\n",
        "print(f\"   RMSE: {test_metrics['rmse']:.6f}\")\n",
        "\n",
        "# Get predictions for visualization\n",
        "predictions_scaled = test_metrics['predictions']\n",
        "output_true_scaled = test_metrics['output_true']\n",
        "\n",
        "print(f\"\\n2️⃣ Prediction Analysis:\")\n",
        "print(f\"   Prediction shape: {predictions_scaled.shape}\")\n",
        "print(f\"   Prediction range: {predictions_scaled.min():.6f} to {predictions_scaled.max():.6f}\")\n",
        "print(f\"   True output range: {output_true_scaled.min():.6f} to {output_true_scaled.max():.6f}\")\n",
        "\n",
        "# Plot predictions vs actual\n",
        "print(f\"\\n3️⃣ Predictions vs Actual Comparison:\")\n",
        "plot_predictions_vs_actual(\n",
        "    predictions_scaled, \n",
        "    output_true_scaled, \n",
        "    ['High', 'Low', 'Close'], \n",
        "    max_samples=1000\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Model evaluation completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Prediction Visualization\n",
        "\n",
        "Visualize model predictions using candlestick charts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Prediction Visualization\n",
        "print(\"📈 VISUALIZING MODEL PREDICTIONS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Select a test sequence for visualization\n",
        "test_idx = 0\n",
        "test_sequence = X_test_scaled[test_idx:test_idx+1]\n",
        "test_output = y_test_scaled[test_idx]\n",
        "\n",
        "print(f\"1️⃣ Test Sequence Analysis:\")\n",
        "print(f\"   Test sequence shape: {test_sequence.shape}\")\n",
        "print(f\"   Test output shape: {test_output.shape}\")\n",
        "\n",
        "# Make prediction\n",
        "prediction_scaled = predict_next_candle(model, test_sequence)\n",
        "print(f\"   Prediction shape: {prediction_scaled.shape}\")\n",
        "\n",
        "# Add Open column to prediction for charting\n",
        "last_close = test_sequence[0, -1, 3]  # Last Close from input\n",
        "prediction_with_open = add_open_to_predictions(prediction_scaled, last_close)\n",
        "print(f\"   Prediction with Open shape: {prediction_with_open.shape}\")\n",
        "\n",
        "# Reshape prediction to (prediction_length, 4) for charting\n",
        "prediction_length = config.prediction_length\n",
        "prediction_reshaped = prediction_with_open.reshape(prediction_length, 4)\n",
        "print(f\"   Prediction reshaped: {prediction_reshaped.shape}\")\n",
        "\n",
        "# Combine input and prediction for continuous charting\n",
        "input_sequence = test_sequence[0]  # Remove batch dimension\n",
        "combined_prediction = np.vstack([input_sequence, prediction_reshaped])\n",
        "\n",
        "print(f\"\\n2️⃣ Creating Prediction Charts:\")\n",
        "\n",
        "# Chart 1: Input + True Output\n",
        "print(\"   📊 Input + True Output Chart:\")\n",
        "true_output_with_open = organizer.add_open_to_output(input_sequence, test_output, config.prediction_length)\n",
        "combined_true = np.vstack([input_sequence, true_output_with_open])\n",
        "draw_candlestick_chart(\n",
        "    combined_true, \n",
        "    'Input + True Output (Ground Truth)', \n",
        "    'Scaled Value'\n",
        ")\n",
        "\n",
        "# Chart 2: Input + Model Prediction\n",
        "print(\"   📊 Input + Model Prediction Chart:\")\n",
        "draw_candlestick_chart(\n",
        "    combined_prediction, \n",
        "    'Input + Model Prediction (Combined)', \n",
        "    'Scaled Value'\n",
        ")\n",
        "\n",
        "print(f\"\\n3️⃣ Prediction Analysis:\")\n",
        "print(f\"   Input range: {input_sequence.min():.6f} to {input_sequence.max():.6f}\")\n",
        "print(f\"   Prediction range: {prediction_reshaped.min():.6f} to {prediction_reshaped.max():.6f}\")\n",
        "print(f\"   True output range: {true_output_with_open.min():.6f} to {true_output_with_open.max():.6f}\")\n",
        "\n",
        "# Calculate prediction accuracy\n",
        "prediction_mae = np.mean(np.abs(prediction_reshaped - true_output_with_open))\n",
        "print(f\"   Prediction MAE: {prediction_mae:.6f}\")\n",
        "\n",
        "print(f\"\\n✅ Prediction visualization completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Performance Summary\n",
        "\n",
        "Display comprehensive model performance metrics and analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Model Performance Summary\n",
        "print(\"📊 MODEL PERFORMANCE SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Training performance\n",
        "print(\"1️⃣ Training Performance:\")\n",
        "print(f\"   Final Training Loss: {history.history['loss'][-1]:.6f}\")\n",
        "print(f\"   Final Validation Loss: {history.history['val_loss'][-1]:.6f}\")\n",
        "print(f\"   Final Training MAE: {history.history['mae'][-1]:.6f}\")\n",
        "print(f\"   Final Validation MAE: {history.history['val_mae'][-1]:.6f}\")\n",
        "\n",
        "# Test performance\n",
        "print(f\"\\n2️⃣ Test Performance:\")\n",
        "print(f\"   Test MSE: {test_metrics['test_loss']:.6f}\")\n",
        "print(f\"   Test MAE: {test_metrics['test_mae']:.6f}\")\n",
        "print(f\"   Test MAPE: {test_metrics['test_mape']:.2f}%\")\n",
        "print(f\"   Test RMSE: {test_metrics['rmse']:.6f}\")\n",
        "\n",
        "# Model architecture\n",
        "print(f\"\\n3️⃣ Model Architecture:\")\n",
        "print(f\"   Input Shape: {input_shape}\")\n",
        "print(f\"   Output Size: {config.prediction_length * 3} (HLC per timestep)\")\n",
        "print(f\"   Total Parameters: {model.count_params():,}\")\n",
        "print(f\"   LSTM Units: {config.lstm_units}\")\n",
        "print(f\"   Dropout Rate: {config.dropout_rate}\")\n",
        "\n",
        "# Data characteristics\n",
        "print(f\"\\n4️⃣ Data Characteristics:\")\n",
        "print(f\"   Training Samples: {X_train_scaled.shape[0]:,}\")\n",
        "print(f\"   Test Samples: {X_test_scaled.shape[0]:,}\")\n",
        "print(f\"   Sequence Length: {config.sequence_length}\")\n",
        "print(f\"   Prediction Length: {config.prediction_length}\")\n",
        "print(f\"   Features: OHLC only (Volume removed)\")\n",
        "print(f\"   Scaling: Expanded range approach\")\n",
        "\n",
        "# Scaling analysis\n",
        "print(f\"\\n5️⃣ Scaling Analysis:\")\n",
        "print(f\"   Input Range: {X_train_scaled.min():.6f} to {X_train_scaled.max():.6f}\")\n",
        "print(f\"   Output Range: {y_train_scaled.min():.6f} to {y_train_scaled.max():.6f}\")\n",
        "print(f\"   Both in 0-1 Range: {np.all(X_train_scaled >= 0) and np.all(X_train_scaled <= 1)}\")\n",
        "\n",
        "print(f\"\\n✅ Model training and evaluation completed successfully!\")\n",
        "print(f\"   The model is ready for production use with the new expanded range scaling approach.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "crypto_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
